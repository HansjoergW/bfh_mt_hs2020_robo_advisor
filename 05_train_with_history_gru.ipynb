{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on https://blog.floydhub.com/gru-with-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List, Tuple, Union, Set\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingset_folder = \"D:/data_mt/09_training/\"\n",
    "stock_data_folder = trainingset_folder + \"stocks/\"\n",
    "stock_potential_folder = trainingset_folder + \"stocks_w_potential/\"\n",
    "gru_model_folder = \"D:/data_mt/09_training/gru_model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Cuda installed:  True\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"Is Cuda installed: \", is_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00_Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Fundamental Data\n",
    "def load_reports(tickers: List[str]):\n",
    "    df = pd.read_csv(trainingset_folder + \"company_reports.csv\", header=0)\n",
    "    df.period = pd.to_datetime(df.period)\n",
    "    df.filed = pd.to_datetime(df.filed)\n",
    "    \n",
    "    \n",
    "    df['i_date'] = df.filed\n",
    "    df.set_index('i_date', inplace = True)\n",
    "    df.sort_index(inplace = True)\n",
    "\n",
    "    return df[df.ticker.isin(tickers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stock_history(ticker: str):\n",
    "    df = pd.read_csv(stock_potential_folder + ticker[0] + \"/\" + ticker + \".csv\")\n",
    "    df.Date = pd.to_datetime(df.Date)\n",
    "    \n",
    "    df = df[df.Date > \"2012-01-01\"]\n",
    "    df['i_date'] = df.Date\n",
    "    df.set_index('i_date', inplace=True)\n",
    "    df.sort_index(inplace = True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_additional_info() -> pd.DataFrame:\n",
    "    return pd.read_csv(trainingset_folder + \"company_info.csv\", sep=',', encoding='utf-8', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01_Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_reports = ['r_workcapToAssets', 'r_currentRatio', 'r_deptToEquity', 'r_deptRatio', 'r_netProfitMargin', 'r_operatingMargin', 'r_netIncomeMargin', \n",
    "            'r_cashGenPowerRatio', 'r_extFinancingIndexRatio', 'r_returnOnEquity', 'r_returnOnAssets', 'r_assetsTurnoverRatio', 'r_dividendPayoutRatio', \n",
    "            'r_stockRepurchaseRatio', 'r_operatingCashFlowRatio', 'r_assetEfficiencyRatio', 'r_currentLiabCoverageRatio', 'r_longtermDeptCoverageRatio',\n",
    "            \n",
    "            # 'gr_revenue_n', 'gr_asscur_n', 'gr_assnoncur_n','gr_liabcur_n', 'gr_liabnoncur_n',\n",
    "            \n",
    "            'gr_revenue_p', 'gr_grosspr_n', 'gr_grosspr_p', 'gr_opiincome_n', 'gr_opiincome_p', 'gr_netincome_n', 'gr_netincome_p', \n",
    "            'gr_earnings_n', 'gr_earnings_p', 'gr_equity_n', 'gr_equity_p', \n",
    "            'gr_asscur_p', 'gr_assnoncur_p', 'gr_liabcur_p',\n",
    "            'gr_liabnoncur_p', 'gr_cashfrominv_n', 'gr_cashfrominv_p', \n",
    "            'gr_cashfromfin_n', 'gr_cashfromfin_p', 'gr_cashfromope_n', 'gr_cashfromope_p', \n",
    "            'gr_dividends_n', 'gr_dividends_p',\n",
    "            \n",
    "            'fp__FY', 'fp__Q1', 'fp__Q2', 'fp__Q3', 'fp__Q4', ]\n",
    "\n",
    "features_stockdata = ['high_norm', 'low_norm', 'open_norm', 'volume_norm', 'close_chg', # 'volume_chg',remove -> inf values and much larger than 1\n",
    "                     'day_of_week', 'day_of_month', 'day_of_year', 'week_of_year', 'month_of_year',\n",
    "                     'pr_p2e_norm', 'pr_p2b_norm', 'pr_p2egr_1y_norm'\n",
    "                     ]\n",
    "\n",
    "features_add_info = [\n",
    "            'sec__BasicMaterials', 'sec__CommunicationServices', 'sec__ConsumerCyclical', 'sec__ConsumerDefensive', 'sec__Energy', 'sec__FinancialServices',\n",
    "            'sec__Healthcare',  'sec__IndustrialGoods', 'sec__Industrials', 'sec__RealEstate', 'sec__Technology', 'sec__Utilities',\n",
    "            \n",
    "            'ind__AerospaceDefense', 'ind__ApparelRetail', 'ind__AssetManagement', 'ind__AutoParts', 'ind__BanksRegional', 'ind__Biotechnology', \n",
    "            'ind__CommunicationEquipment',              'ind__CreditServices', 'ind__DiagnosticsResearch', 'ind__ElectronicComponents', \n",
    "            'ind__InformationTechnologyServices', 'ind__InsurancePropertyCasualty', 'ind__MedicalDevices', 'ind__MedicalInstrumentsSupplies',\n",
    "            'ind__OilGasEP', 'ind__OilGasEquipmentServices', 'ind__OilGasMidstream', 'ind__Other', 'ind__PackagedFoods', 'ind__Restaurants',\n",
    "            'ind__ScientificTechnicalInstruments', 'ind__SemiconductorEquipmentMaterials', 'ind__Semiconductors', 'ind__SoftwareApplication',\n",
    "            'ind__SoftwareInfrastructure', 'ind__SpecialtyBusinessServices', 'ind__SpecialtyChemicals', 'ind__SpecialtyIndustrialMachinery',\n",
    "            'ind__SpecialtyRetail',\n",
    "\n",
    "            'mc_top10', 'mc_top20', 'mc_top30', 'mc_top50','mc_top100','mc_top200']\n",
    "\n",
    "tabular_features = list(features_stockdata)\n",
    "tabular_features.extend(features_add_info)\n",
    "\n",
    "label = 'r_potential'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_info = load_additional_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "497"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers_to_process_test = ['AAPL', 'MSFT']\n",
    "tickers_to_process_all = add_info[add_info.mc_top500 == 1.0].ticker.unique()\n",
    "len(tickers_to_process_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16542, 85)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# laod all reports\n",
    "reports_df = load_reports(tickers_to_process_all)\n",
    "reports_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports_features_scaler = MinMaxScaler()\n",
    "reports_features_scaler.fit(reports_df[features_reports])\n",
    "\n",
    "stock_features_scaler = MinMaxScaler()\n",
    "\n",
    "labels_scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_of_features = len(features_reports)\n",
    "lookback_size = 8\n",
    "\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02_build dataset\n",
    "Prepare the train and testdata.<br>\n",
    "Out of the financial data from the reports sequences of 8 reports are created and then matched based on the filed date of the latest report in the sequence. This one will be refered to as \"series_x\" in the code. <br>\n",
    "Furthermore, the features of the historical stockdata are combined with the data read from the \"add_info\". These will be refered as \"features_x\".<br>\n",
    "So for every day that there are 61 'tabular' features (historical stockdata and add_info) and a sequence of data from 8 reports with 46 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "def save_scaler(scaler, filename):\n",
    "    joblib.dump(scaler, filename) \n",
    "    \n",
    "def load_scaler(filename):\n",
    "    return joblib.load(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequence_series(reports_ticker_df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    creates the timeseries arrays based on the features in the provided dataframe.\n",
    "    returns them as a pandas series, so that they can be merged with other data\n",
    "    \"\"\"\n",
    "    # scale the data, float32 should be enough\n",
    "    np_feature_rows = reports_features_scaler.transform(reports_ticker_df[features_reports]).astype(np.float32)\n",
    "    \n",
    "    nr_of_rows      = np_feature_rows.shape[0]\n",
    "    nr_of_sequences = nr_of_rows - lookback_size + 1 # example: if there are 8 rows and the lookback size is 8, we can create 1 timeseries arr\n",
    "\n",
    "    # create empty array to hold the data\n",
    "    feature_seq_arr = np.zeros((nr_of_sequences, lookback_size, nr_of_features))\n",
    "    \n",
    "    # create the timeseries (sequences) arrays\n",
    "    for i in range(0, nr_of_sequences):\n",
    "        feature_seq_arr[i] = np_feature_rows[i : i + lookback_size]\n",
    "    \n",
    "    # convert into pandas series, there might be a more efficient way, but it works\n",
    "    flat_input = feature_seq_arr.reshape(-1, lookback_size * nr_of_features)    \n",
    "    pd_features_col = pd.Series(flat_input.tolist(), name='features').apply(lambda field: np.array(field).reshape(lookback_size, nr_of_features))\n",
    "\n",
    "    return pd_features_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_forward = ['filed', 'c_NetIncomeLoss', 'c_PaymentsOfDividendsTotal', 'Assets', 'Liabilities', 'gr_netincome_p']\n",
    "\n",
    "def merge_report_data_with_sequence_series(reports_ticker_df: pd.DataFrame, pd_features_col: pd.Series) -> pd.DataFrame:\n",
    "    \n",
    "    # only select those cols, which are needed for the further processing, drop index, so that the feature col can be added\n",
    "    reports_ticker_merge_df = reports_ticker_df[lookback_size - 1:][features_to_forward].reset_index(drop=True)\n",
    "    \n",
    "    df_combined = pd.concat([reports_ticker_merge_df, pd_features_col], axis=1)\n",
    "    df_combined['i_date'] = df_combined.filed\n",
    "    df_combined.set_index('i_date', inplace=True)\n",
    "    \n",
    "    return df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_stock_data(pd_combined_df: pd.DataFrame, stock_data_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_with_stock = pd.merge(pd_combined_df, stock_data_df, left_index=True, right_index=True, how='outer')\n",
    "    df_with_stock.sort_index(inplace=True)\n",
    "    \n",
    "    df_with_stock = df_with_stock.fillna(method=\"ffill\")\n",
    "    df_with_stock = df_with_stock.dropna(subset=['filed', 'Date'])\n",
    "    return df_with_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_price_ratio_features_in_place(combined_data: pd.DataFrame, shares_outstanding:int):\n",
    "    \"\"\"Calculates stock price depending features. \n",
    "    \"\"\"\n",
    "    \n",
    "    combined_data['pr_p2e'] = combined_data.Close * shares_outstanding / (\n",
    "            combined_data.c_NetIncomeLoss - combined_data.c_PaymentsOfDividendsTotal)\n",
    "    \n",
    "    combined_data['pr_p2b'] = combined_data.Close * shares_outstanding / (\n",
    "            combined_data.Assets - combined_data.Liabilities)\n",
    "    \n",
    "    combined_data['pr_p2egr_1y'] = combined_data.pr_p2e / (\n",
    "            combined_data.gr_netincome_p * 100)  # approximated / denominator in percent\n",
    "\n",
    "    # caping p2e: in order to prevent meaningless values, we need to restrict the range. The max value is limited to 100.\n",
    "    # if new_df.c_NetIncomeLoss - new_df.c_PaymentsOfDividendsTotal results in a negativ value, we set p2e to 100, which is rather a \"bad\" value.\n",
    "    combined_data.loc[(combined_data.pr_p2e < 0) | (combined_data.pr_p2e > 100), 'pr_p2e'] = 100\n",
    "    \n",
    "    # caping p2egr: the lower the better. generally you would like to see a ratio lower than 1, so a 5 can be considered a really bad value so we restrict it to 5\n",
    "    # if growth number is 0 or less, we set p2egr to 5\n",
    "    combined_data.loc[(combined_data.pr_p2egr_1y > 5) | (combined_data.pr_p2egr_1y <= 0.0), 'pr_p2egr_1y'] = 5\n",
    "    \n",
    "    # normalize\n",
    "    combined_data['pr_p2e_norm'] = combined_data['pr_p2e'] / 100  # 100 is the max as defined above\n",
    "    combined_data['pr_p2b_norm'] = combined_data['pr_p2b'] / 100  # p2b of 100 is pretty extreme, values above are very rare\n",
    "    combined_data['pr_p2egr_1y_norm'] = combined_data['pr_p2egr_1y'] / 5  # 5 is max as defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_set_for_ticker(ticker) -> pd.DataFrame:\n",
    "    add_info_ticker = add_info[add_info.ticker == ticker]\n",
    "    reports_ticker_df = reports_df[reports_df.ticker == ticker]\n",
    "    stock_data_df = load_stock_history(ticker)\n",
    "      \n",
    "    pd_features_col = create_sequence_series(reports_ticker_df)\n",
    "    pd_combined_df = merge_report_data_with_sequence_series(reports_ticker_df, pd_features_col)\n",
    "    pd_with_stock_df = merge_stock_data(pd_combined_df, stock_data_df)\n",
    "    \n",
    "    shares_outstanding = add_info_ticker.sharesOutstanding.to_list()[0]\n",
    "    create_price_ratio_features_in_place(pd_with_stock_df, shares_outstanding)\n",
    "    \n",
    "    pd_complete_df = pd.merge(pd_with_stock_df, add_info_ticker, how=\"outer\", on=\"ticker\")\n",
    "    \n",
    "    return pd_complete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_test_train_values(series_x, features_x, y, pd_ticker):\n",
    "    \n",
    "    arr_of_arr_of_series_features = pd_ticker.features.to_numpy()\n",
    "    series_x_ticker = np.concatenate(arr_of_arr_of_series_features) \\\n",
    "                              .reshape(arr_of_arr_of_series_features.shape[0], lookback_size, nr_of_features)\n",
    "\n",
    "    features_x_ticker = pd_ticker[tabular_features].to_numpy()\n",
    "\n",
    "    y_ticker = pd_ticker.r_potential.to_numpy()\n",
    "\n",
    "    if len(y) == 0:\n",
    "        series_x   = series_x_ticker\n",
    "        features_x = features_x_ticker\n",
    "        y          = y_ticker\n",
    "    else:\n",
    "        series_x   = np.concatenate((series_x, series_x_ticker))\n",
    "        features_x = np.concatenate((features_x, features_x_ticker))\n",
    "        y          = np.concatenate((y, y_ticker))\n",
    "    \n",
    "    return series_x, features_x, y   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_testset(tickers: List[str]):\n",
    "    \n",
    "    # traindaten < 1.1.2018\n",
    "    # traindaten nur jedes 2. nehmen\n",
    "    # traindaten label -> muss am Ende normalisiert werden\n",
    "    # => 3 numpy Arrays\n",
    "    #    timeseries arrays\n",
    "    #    tables arrays\n",
    "    #    labels arrays\n",
    "    # testdaten >= 1.1.2018 -> können als Pandas bleiben, oder?\n",
    "    \n",
    "    train_series_x   = [] # timeseries features\n",
    "    train_features_x = [] # tabular features\n",
    "    train_y          = [] # target label\n",
    "    \n",
    "    test_series_x    = []\n",
    "    test_features_x  = []\n",
    "    test_y           = []\n",
    "    test_pd_list     = []\n",
    "    \n",
    "    \n",
    "    for ticker in tickers:\n",
    "        print(ticker, end=\",\")\n",
    "        pd_complete_ticker = build_set_for_ticker(ticker)\n",
    "        pd_train_ticker = pd_complete_ticker[pd_complete_ticker.filed < \"2018-01-01\"]\n",
    "        pd_test_ticker = pd_complete_ticker[pd_complete_ticker.filed  >= \"2018-01-01\"]\n",
    "        \n",
    "        if pd_train_ticker.shape[0] > 0:\n",
    "            train_series_x, train_features_x, train_y  = \\\n",
    "                add_test_train_values(train_series_x, train_features_x, train_y, pd_train_ticker)\n",
    "        \n",
    "        if pd_test_ticker.shape[0] > 0:\n",
    "            test_pd_list.append(pd_test_ticker)\n",
    "            test_series_x, test_features_x, test_y = \\\n",
    "                    add_test_train_values(test_series_x, test_features_x, test_y, pd_test_ticker)\n",
    "    \n",
    "    \n",
    "    return train_series_x, train_features_x, train_y, test_series_x, test_features_x, test_y, test_pd_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,AAL,AAPL,ABBV,ABC,ABMD,ABT,ACAD,ACGL,ACN,ADBE,ADI,ADP,ADSK,AES,AFL,AGNC,AIG,AJG,AKAM,ALB,ALGN,ALL,ALLE,ALNY,ALV,ALXN,AMAT,AMD,AME,AMED,AMGN,AMH,AMP,AMT,AMZN,ANSS,AOS,APD,APH,APO,ARE,ARMK,ATO,ATR,ATVI,AVB,AVGO,AVY,AWK,AZPN,BA,BAC,BAH,BAX,BBY,BDX,BEN,BFAM,BG,BIIB,BIO,BK,BLK,BLL,BMRN,BMY,BR,BRKR,BRO,BSX,BURL,BWA,BX,BXP,C,CAG,CAH,CAT,CBOE,CCC,CCI,CCK,CCL,CDNS,CDW,CE,CERN,CF,CHD,CHGG,CHRW,CHTR,CI,CINF,CL,CLX,CMCSA,CME,CMG,CMI,CMS,CNA,CNC,CNP,COF,COO,COST,CPB,CPRT,CPT,CQP,CREE,CRM,CSCO,CSL,CSX,CTAS,CTSH,CTXS,CVS,CVX,CXO,CZR,D,DAL,DAR,DE,DECK,DFS,DG,DGX,DHI,DHR,DIS,DISCA,DISH,DLB,DLR,DLTR,DNKN,DOV,DOW,DPZ,DRE,DRI,DTE,DUK,DVA,DXCM,EA,EBAY,ECL,ED,EFX,EIX,EL,ELS,EMN,EMR,ENPH,ENTG,EOG,EPAM,EPD,EQIX,EQR,ERIE,ESS,ETR,EW,EXAS,EXC,EXPD,EXPE,EXR,FANG,FAST,FATE,FB,FBHS,FCX,FDS,FDX,FE,FFIV,FICO,FIS,FITB,FIVE,FLEX,FLT,FMC,FSLR,FTNT,GGG,GILD,GIS,GM,GNRC,GNTX,GPC,GPN,GPS,GRMN,GS,GWRE,GWW,HAL,HAS,HBAN,HCA,HD,HDS,HEI,HES,HIG,HLT,HOLX,HON,HPQ,HRL,HSIC,HSY,HUM,HZNP,IBKR,IBM,IDXX,IEP,IEX,IFF,ILMN,INCY,INTC,INTU,IP,IPG,IPGP,IR,IRM,ISRG,IT,IVZ,JAZZ,JBHT,JCI,JKHY,JNJ,JPM,K,KEY,KKR,KLAC,KMB,KMI,KO,KSU,L,LAMR,LDOS,LEA,LEN,LH,LII,LKQ,LLY,LMT,LNC,LNG,LNT,LOGI,LOW,LPLA,LRCX,LULU,LUV,LVS,LYB,LYV,MA,MAR,MAS,MASI,MCD,MCHP,MCK,MCO,MDLZ,MELI,MET,MGM,MHK,MKC,MKL,MKSI,MKTX,MLM,MMC,MMM,MO,MOH,MORN,MPC,MPLX,MPW,MPWR,MRK,MRTX,MRVL,MS,MSCI,MSFT,MSI,MTB,MTD,MTN,MU,MXIM,NBIX,NCLH,NDAQ,NDSN,NEE,NEM,NFLX,NKE,NLY,NOW,NRG,NSC,NTAP,NTRS,NUAN,NUE,NVAX,NVDA,NVR,NWL,NWS,NYT,O,OC,ODFL,OKE,OMC,ORCL,ORLY,OXY,PANW,PAYX,PCAR,PCG,PEG,PEGA,PENN,PEP,PFE,PFG,PG,PGR,PH,PKG,PKI,PM,PNC,PNW,PODD,POOL,PPG,PPL,PRU,PSA,PTC,PWR,QCOM,RARE,RE,REGN,RF,RGA,RGEN,RH,RJF,RMD,RNG,RNR,ROK,ROL,ROP,ROST,RPM,RSG,SAM,SBAC,SBUX,SCCO,SCHW,SCI,SE,SEIC,SGEN,SHW,SIRI,SIVB,SJM,SLB,SMG,SNA,SNPS,SPG,SPLK,SRE,SRPT,SSNC,STLD,STT,STX,STZ,SUI,SWK,SYK,SYY,TAL,TAP,TDG,TDY,TEL,TER,TFX,TGT,TIF,TJX,TMO,TMUS,TREX,TRMB,TROW,TRV,TSCO,TSLA,TSN,TTC,TTWO,TWTR,TXN,TXT,TYL,UAL,UDR,UHAL,UHS,ULTA,UNH,UNP,UPS,URI,USB,V,VAR,VEEV,VFC,VLO,VMC,VRSK,VRSN,VRTX,VTR,VZ,WAB,WCN,WDAY,WDC,WEC,WEX,WFC,WHR,WLK,WM,WMB,WMT,WPC,WSM,WSO,WST,WU,WY,WYNN,XEL,XLNX,XOM,XPO,XRAY,XYL,Y,ZNGA,ZTS,Train Series   :  (488112, 8, 46)\n",
      "Train Features :  (488112, 60)\n",
      "Train Label    :  (488112,)\n",
      "Test  Series   :  (347354, 8, 46)\n",
      "Test  Features :  (347354, 60)\n",
      "Test  Label    :  (347354,)\n",
      "Test  Parts    :  492\n"
     ]
    }
   ],
   "source": [
    "train_series_x, train_features_x, train_y, test_series_x, test_features_x, test_y, test_pd_list = \\\n",
    "    build_train_testset(tickers_to_process_all)\n",
    "\n",
    "print(\"Train Series   : \", train_series_x.shape)\n",
    "print(\"Train Features : \", train_features_x.shape)\n",
    "print(\"Train Label    : \", train_y.shape)\n",
    "print(\"Test  Series   : \", test_series_x.shape)\n",
    "print(\"Test  Features : \", test_features_x.shape)\n",
    "print(\"Test  Label    : \", test_y.shape)\n",
    "print(\"Test  Parts    : \", len(test_pd_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_y = np.hstack((train_y, test_y))\n",
    "labels_scaler.fit(all_y.reshape(-1,1))\n",
    "\n",
    "train_y = labels_scaler.transform(train_y.reshape(-1,1)).ravel()\n",
    "test_y  = labels_scaler.transform(test_y.reshape(-1,1)).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the stock features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = np.vstack((train_features_x, test_features_x))\n",
    "\n",
    "stock_features_scaler.fit(all_features)\n",
    "train_features_x = stock_features_scaler.transform(train_features_x)\n",
    "test_features_x = stock_features_scaler.transform(test_features_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce trainset\n",
    "in general, neighboring points are very similar since only the stock price change and all other data (add_info, series of fundamental data) stay the same. So using just half of the points should accelerate the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_series_x   = train_series_x[::2]\n",
    "train_features_x = train_features_x[::2]\n",
    "train_y          = train_y[::2].reshape(-1,1) # the model output will produce a 2dim array with just one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(torch.from_numpy(train_series_x), torch.from_numpy(train_features_x), torch.from_numpy(train_y))\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check data\n",
    "4: 'volume_norm', \n",
    "5: 'close_chg', \n",
    "6: 'volume_chg',\n",
    "10:'week_of_year' max 1.02\n",
    "13: 'pr_p2b_norm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(train_features_x[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(sum(np.isinf(train_features_x))) # 6:4\n",
    "print(sum(train_features_x >  1.0)) # 4:1 5:1 6:12104 10:970 13:1196\n",
    "print(sum(train_features_x < -1.0)) # 13:785"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min  / max train_series_x:  0.0  /  1.0\n",
      "min  / max train_features_x:  0.0  /  1.0\n",
      "min  / max train_y:  0.0  /  0.3721950455695225\n"
     ]
    }
   ],
   "source": [
    "print(\"min  / max train_series_x: \", np.min(train_series_x), \" / \", np.max(train_series_x))\n",
    "print(\"min  / max train_features_x: \", np.min(train_features_x), \" / \", np.max(train_features_x))\n",
    "print(\"min  / max train_y: \", np.min(train_y), \" / \", np.max(train_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03_Define Model\n",
    "https://discuss.pytorch.org/t/combine-two-model-on-pytorch/47858/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_input_dim = nr_of_features # 46\n",
    "gru_hidden_dim = 128\n",
    "gru_output_dim = gru_input_dim\n",
    "gru_n_layers   = 2\n",
    "\n",
    "feat_input_dim = len(tabular_features)\n",
    "feat_hidden_dim = 128\n",
    "feat_output_dim = len(tabular_features)\n",
    "\n",
    "combine_hidden_dim = 32\n",
    "combine_output_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as defined in https://blog.floydhub.com/gru-with-pytorch/\n",
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n",
    "        super(GRUNet, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        out, h = self.gru(x, h)\n",
    "        out = self.fc(self.relu(out[:,-1]))\n",
    "        return out, h\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TrainNet, self).__init__()\n",
    "        \n",
    "        self.series_model = GRUNet(gru_input_dim, gru_hidden_dim, gru_output_dim, gru_n_layers)\n",
    "        self.current_h_data = None\n",
    "        \n",
    "        self.features_model = nn.Sequential(\n",
    "            nn.Linear(feat_input_dim, feat_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(feat_hidden_dim, feat_output_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.combine_model = nn.Sequential(\n",
    "            nn.Linear(feat_output_dim + gru_output_dim, combine_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(combine_hidden_dim, combine_output_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        self.current_h_data = self.series_model.init_hidden(batch_size).data\n",
    "\n",
    "\n",
    "    def forward(self, series_data, features_data):\n",
    "        series_x, h  = self.series_model(series_data, self.current_h_data)\n",
    "        features_x   = self.features_model(features_data)\n",
    "\n",
    "        self.current_h_data = h.data\n",
    "        \n",
    "        # print(series_x.size())\n",
    "        # print(series_x.size())\n",
    "        \n",
    "        x = torch.cat((series_x, features_x), 1)\n",
    "        x = self.combine_model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fragen:\n",
    "- warum wird h im TrainLoop hidden in jeder Epoche neu initialisiert? Warum erfolgt das nicht nur ausserhalb?\n",
    "- wozu ist h überhaupt da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, learn_rate, save_path = None, EPOCHS=5):\n",
    "    model = TrainNet()\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
    "    \n",
    "    print(\"Starting Training of model\")\n",
    "    model.train()\n",
    "    \n",
    "    epoch_times = []\n",
    "    total_loss_list = []\n",
    "    avg_loss_list = []\n",
    "    \n",
    "    # Start training loop\n",
    "    for epoch in range(1,EPOCHS+1):\n",
    "        start_time = time.perf_counter()\n",
    "        model.init_hidden(batch_size)\n",
    "        \n",
    "        total_loss = 0.\n",
    "        counter = 0\n",
    "        \n",
    "        for series_x, features_x, label in train_loader:\n",
    "            counter += 1\n",
    "            model.zero_grad()\n",
    "            \n",
    "            out = model(series_x.to(device).float(), features_x.to(device).float())\n",
    "            \n",
    "            #print(\"out:   \", out.size())\n",
    "            #print(\"label: \", label.size())\n",
    "            \n",
    "            loss = criterion(out, label.to(device).float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_item = loss.item()\n",
    "            \n",
    "            total_loss += loss_item\n",
    "            \n",
    "            if counter%1000 == 0:\n",
    "                print(\"loss_item: \", loss_item, end=\" - \")\n",
    "                print(\"Epoch {}......Step: {}/{}....... Average Loss for Epoch: {}\".format(epoch, counter, len(train_loader), total_loss/counter))\n",
    "        \n",
    "        current_time = time.perf_counter()\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "       \n",
    "        avg_loss_list.append(avg_loss)\n",
    "        total_loss_list.append(total_loss)\n",
    "        \n",
    "        print(\"Epoch {}/{} Done, Total Loss: {}\".format(epoch, EPOCHS, avg_loss ))\n",
    "        print(\"Total Time Elapsed: {} seconds\".format(str(current_time-start_time)))\n",
    "       \n",
    "        epoch_times.append(current_time-start_time)\n",
    "\n",
    "        if save_path is not None:\n",
    "            # https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "            torch.save(model.state_dict(), os.path.join(save_path, \"epoch_\" + str(epoch)+\".model\"))\n",
    "        \n",
    "    print(\"Total Training Time: {} seconds\".format(str(sum(epoch_times))))\n",
    "    return model, avg_loss_list, total_loss_list, epoch_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/nan-loss-coming-after-some-time/11568/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training of model\n",
      "loss_item:  0.00014677629224024713 - Epoch 1......Step: 1000/3813....... Average Loss for Epoch: 7.6462502924187e-05\n",
      "loss_item:  3.88794724131003e-05 - Epoch 1......Step: 2000/3813....... Average Loss for Epoch: 7.312673056048879e-05\n",
      "loss_item:  3.36424564011395e-05 - Epoch 1......Step: 3000/3813....... Average Loss for Epoch: 6.9861439399574e-05\n",
      "Epoch 1/30 Done, Total Loss: 6.733909805674141e-05\n",
      "Total Time Elapsed: 29.416411100002733 seconds\n",
      "loss_item:  3.152786666760221e-05 - Epoch 2......Step: 1000/3813....... Average Loss for Epoch: 5.257719796645688e-05\n",
      "loss_item:  2.0588468032656237e-05 - Epoch 2......Step: 2000/3813....... Average Loss for Epoch: 5.060403920924728e-05\n",
      "loss_item:  3.213897434761748e-05 - Epoch 2......Step: 3000/3813....... Average Loss for Epoch: 4.8123375827344716e-05\n",
      "Epoch 2/30 Done, Total Loss: 4.680843770506684e-05\n",
      "Total Time Elapsed: 29.693229500000598 seconds\n",
      "loss_item:  8.75063196872361e-05 - Epoch 3......Step: 1000/3813....... Average Loss for Epoch: 3.95608936669305e-05\n",
      "loss_item:  2.1230534912319854e-05 - Epoch 3......Step: 2000/3813....... Average Loss for Epoch: 3.789398471826644e-05\n",
      "loss_item:  6.81181118125096e-05 - Epoch 3......Step: 3000/3813....... Average Loss for Epoch: 3.717806670404873e-05\n",
      "Epoch 3/30 Done, Total Loss: 3.680777385362539e-05\n",
      "Total Time Elapsed: 31.31472919999942 seconds\n",
      "loss_item:  2.4414741346845403e-05 - Epoch 4......Step: 1000/3813....... Average Loss for Epoch: 3.196687785657559e-05\n",
      "loss_item:  4.15609210904222e-05 - Epoch 4......Step: 2000/3813....... Average Loss for Epoch: 3.202234333821252e-05\n",
      "loss_item:  2.2396976419258863e-05 - Epoch 4......Step: 3000/3813....... Average Loss for Epoch: 3.1405873103722115e-05\n",
      "Epoch 4/30 Done, Total Loss: 3.141994933104963e-05\n",
      "Total Time Elapsed: 30.043660499999532 seconds\n",
      "loss_item:  2.186452184105292e-05 - Epoch 5......Step: 1000/3813....... Average Loss for Epoch: 2.7617184776318026e-05\n",
      "loss_item:  1.55535526573658e-05 - Epoch 5......Step: 2000/3813....... Average Loss for Epoch: 2.8187663158860233e-05\n",
      "loss_item:  4.18861563957762e-05 - Epoch 5......Step: 3000/3813....... Average Loss for Epoch: 2.8519824610460396e-05\n",
      "Epoch 5/30 Done, Total Loss: 2.8013366478957052e-05\n",
      "Total Time Elapsed: 32.03026730000056 seconds\n",
      "loss_item:  1.0956697224173695e-05 - Epoch 6......Step: 1000/3813....... Average Loss for Epoch: 2.5963209453038872e-05\n",
      "loss_item:  5.031278124079108e-05 - Epoch 6......Step: 2000/3813....... Average Loss for Epoch: 2.597338669988858e-05\n",
      "loss_item:  2.0393586964928545e-05 - Epoch 6......Step: 3000/3813....... Average Loss for Epoch: 2.532211372257128e-05\n",
      "Epoch 6/30 Done, Total Loss: 2.501712684350954e-05\n",
      "Total Time Elapsed: 30.170918600000732 seconds\n",
      "loss_item:  1.5211120626190677e-05 - Epoch 7......Step: 1000/3813....... Average Loss for Epoch: 2.3997634391434984e-05\n",
      "loss_item:  1.5499281289521605e-05 - Epoch 7......Step: 2000/3813....... Average Loss for Epoch: 2.399918110108956e-05\n",
      "loss_item:  8.245513527072035e-06 - Epoch 7......Step: 3000/3813....... Average Loss for Epoch: 2.374262769959993e-05\n",
      "Epoch 7/30 Done, Total Loss: 2.3346962836499474e-05\n",
      "Total Time Elapsed: 29.888217200001236 seconds\n",
      "loss_item:  1.5144830285862554e-05 - Epoch 8......Step: 1000/3813....... Average Loss for Epoch: 2.1965011801967194e-05\n",
      "loss_item:  2.0891213353024796e-05 - Epoch 8......Step: 2000/3813....... Average Loss for Epoch: 2.1500060738617323e-05\n",
      "loss_item:  3.62782011507079e-05 - Epoch 8......Step: 3000/3813....... Average Loss for Epoch: 2.1672596086621827e-05\n",
      "Epoch 8/30 Done, Total Loss: 2.14205740203595e-05\n",
      "Total Time Elapsed: 30.16913370000111 seconds\n",
      "loss_item:  2.1542258764384314e-05 - Epoch 9......Step: 1000/3813....... Average Loss for Epoch: 2.066161578295578e-05\n",
      "loss_item:  1.8128877854906023e-05 - Epoch 9......Step: 2000/3813....... Average Loss for Epoch: 2.074060933364308e-05\n",
      "loss_item:  1.1810594514827244e-05 - Epoch 9......Step: 3000/3813....... Average Loss for Epoch: 2.0278496064292994e-05\n",
      "Epoch 9/30 Done, Total Loss: 2.0010433935220032e-05\n",
      "Total Time Elapsed: 29.871526099999755 seconds\n",
      "loss_item:  1.4260000170907006e-05 - Epoch 10......Step: 1000/3813....... Average Loss for Epoch: 1.880081463832539e-05\n",
      "loss_item:  1.2425322893250268e-05 - Epoch 10......Step: 2000/3813....... Average Loss for Epoch: 1.931125710757442e-05\n",
      "loss_item:  7.754197213216685e-06 - Epoch 10......Step: 3000/3813....... Average Loss for Epoch: 1.905155594916626e-05\n",
      "Epoch 10/30 Done, Total Loss: 1.885858300538258e-05\n",
      "Total Time Elapsed: 30.201072799998656 seconds\n",
      "loss_item:  7.255981472553685e-06 - Epoch 11......Step: 1000/3813....... Average Loss for Epoch: 1.7668640458396113e-05\n",
      "loss_item:  1.1514906873344444e-05 - Epoch 11......Step: 2000/3813....... Average Loss for Epoch: 1.7829126597462163e-05\n",
      "loss_item:  1.1630923836492002e-05 - Epoch 11......Step: 3000/3813....... Average Loss for Epoch: 1.8126047833296374e-05\n",
      "Epoch 11/30 Done, Total Loss: 1.7915810847763225e-05\n",
      "Total Time Elapsed: 30.562255800003186 seconds\n",
      "loss_item:  2.4147371732397005e-05 - Epoch 12......Step: 1000/3813....... Average Loss for Epoch: 1.7869764700662928e-05\n",
      "loss_item:  7.79289985075593e-06 - Epoch 12......Step: 2000/3813....... Average Loss for Epoch: 1.7120498704798593e-05\n",
      "loss_item:  2.730839878495317e-05 - Epoch 12......Step: 3000/3813....... Average Loss for Epoch: 1.750627104108086e-05\n",
      "Epoch 12/30 Done, Total Loss: 1.734096867099972e-05\n",
      "Total Time Elapsed: 29.82990720000089 seconds\n",
      "loss_item:  1.3412562111625448e-05 - Epoch 13......Step: 1000/3813....... Average Loss for Epoch: 1.7007273591389095e-05\n",
      "loss_item:  9.652449989516754e-06 - Epoch 13......Step: 2000/3813....... Average Loss for Epoch: 1.658608758907576e-05\n",
      "loss_item:  7.936684596643317e-06 - Epoch 13......Step: 3000/3813....... Average Loss for Epoch: 1.6576642328800516e-05\n",
      "Epoch 13/30 Done, Total Loss: 1.6419905711952865e-05\n",
      "Total Time Elapsed: 31.052442299998802 seconds\n",
      "loss_item:  6.070973176974803e-05 - Epoch 14......Step: 1000/3813....... Average Loss for Epoch: 1.521761262029031e-05\n",
      "loss_item:  6.360320185194723e-06 - Epoch 14......Step: 2000/3813....... Average Loss for Epoch: 1.5024308306010425e-05\n",
      "loss_item:  1.8779510355670936e-05 - Epoch 14......Step: 3000/3813....... Average Loss for Epoch: 1.5499636392784548e-05\n",
      "Epoch 14/30 Done, Total Loss: 1.5882689089256916e-05\n",
      "Total Time Elapsed: 33.21194219999961 seconds\n",
      "loss_item:  1.2607946700882167e-05 - Epoch 15......Step: 1000/3813....... Average Loss for Epoch: 1.5773769172938046e-05\n",
      "loss_item:  1.180226627184311e-05 - Epoch 15......Step: 2000/3813....... Average Loss for Epoch: 1.57631088530934e-05\n",
      "loss_item:  8.770677595748566e-06 - Epoch 15......Step: 3000/3813....... Average Loss for Epoch: 1.5470451166720522e-05\n",
      "Epoch 15/30 Done, Total Loss: 1.529271739591606e-05\n",
      "Total Time Elapsed: 30.884231800002453 seconds\n",
      "loss_item:  5.924842298554722e-06 - Epoch 16......Step: 1000/3813....... Average Loss for Epoch: 1.5052970064061811e-05\n",
      "loss_item:  1.0398880476714112e-05 - Epoch 16......Step: 2000/3813....... Average Loss for Epoch: 1.4823873425257262e-05\n",
      "loss_item:  9.981283255910967e-06 - Epoch 16......Step: 3000/3813....... Average Loss for Epoch: 1.5138490651528021e-05\n",
      "Epoch 16/30 Done, Total Loss: 1.491279346924432e-05\n",
      "Total Time Elapsed: 32.80630530000053 seconds\n",
      "loss_item:  9.236321602656972e-06 - Epoch 17......Step: 1000/3813....... Average Loss for Epoch: 1.3795325284945648e-05\n",
      "loss_item:  8.835140761220828e-06 - Epoch 17......Step: 2000/3813....... Average Loss for Epoch: 1.3865401328530425e-05\n",
      "loss_item:  8.292077836813405e-06 - Epoch 17......Step: 3000/3813....... Average Loss for Epoch: 1.427255282040581e-05\n",
      "Epoch 17/30 Done, Total Loss: 1.4393003082272197e-05\n",
      "Total Time Elapsed: 30.585255900001357 seconds\n",
      "loss_item:  1.593795786902774e-05 - Epoch 18......Step: 1000/3813....... Average Loss for Epoch: 1.3530165683278028e-05\n",
      "loss_item:  1.2541158866952173e-05 - Epoch 18......Step: 2000/3813....... Average Loss for Epoch: 1.428034771856801e-05\n",
      "loss_item:  0.00011617750715231523 - Epoch 18......Step: 3000/3813....... Average Loss for Epoch: 1.4068727328625148e-05\n",
      "Epoch 18/30 Done, Total Loss: 1.4080886348294121e-05\n",
      "Total Time Elapsed: 30.96052580000105 seconds\n",
      "loss_item:  7.094093234627508e-06 - Epoch 19......Step: 1000/3813....... Average Loss for Epoch: 1.451984992263533e-05\n",
      "loss_item:  8.693826202943455e-06 - Epoch 19......Step: 2000/3813....... Average Loss for Epoch: 1.3731936515114284e-05\n",
      "loss_item:  1.5556172002106905e-05 - Epoch 19......Step: 3000/3813....... Average Loss for Epoch: 1.3859431389088665e-05\n",
      "Epoch 19/30 Done, Total Loss: 1.3802988816982289e-05\n",
      "Total Time Elapsed: 30.525693399999 seconds\n",
      "loss_item:  3.289595042588189e-05 - Epoch 20......Step: 1000/3813....... Average Loss for Epoch: 1.2942210511027952e-05\n",
      "loss_item:  1.1222784451092593e-05 - Epoch 20......Step: 2000/3813....... Average Loss for Epoch: 1.3430836104475929e-05\n",
      "loss_item:  7.021399142104201e-06 - Epoch 20......Step: 3000/3813....... Average Loss for Epoch: 1.3303862360013833e-05\n",
      "Epoch 20/30 Done, Total Loss: 1.3414992265010381e-05\n",
      "Total Time Elapsed: 29.85618269999759 seconds\n",
      "loss_item:  6.267575827223482e-06 - Epoch 21......Step: 1000/3813....... Average Loss for Epoch: 1.1985984275952433e-05\n",
      "loss_item:  8.315117156598717e-06 - Epoch 21......Step: 2000/3813....... Average Loss for Epoch: 1.3072839969936467e-05\n",
      "loss_item:  6.003442649671342e-06 - Epoch 21......Step: 3000/3813....... Average Loss for Epoch: 1.2996086000233238e-05\n",
      "Epoch 21/30 Done, Total Loss: 1.296491535546679e-05\n",
      "Total Time Elapsed: 29.64322639999955 seconds\n",
      "loss_item:  5.031285581935663e-06 - Epoch 22......Step: 1000/3813....... Average Loss for Epoch: 1.2719260186713654e-05\n",
      "loss_item:  9.090861567528918e-06 - Epoch 22......Step: 2000/3813....... Average Loss for Epoch: 1.294020515979355e-05\n",
      "loss_item:  8.387639536522329e-05 - Epoch 22......Step: 3000/3813....... Average Loss for Epoch: 1.2783701516582369e-05\n",
      "Epoch 22/30 Done, Total Loss: 1.2595070844375165e-05\n",
      "Total Time Elapsed: 29.58488429999852 seconds\n",
      "loss_item:  7.58939677325543e-06 - Epoch 23......Step: 1000/3813....... Average Loss for Epoch: 1.2684879046901187e-05\n",
      "loss_item:  5.451395281852456e-06 - Epoch 23......Step: 2000/3813....... Average Loss for Epoch: 1.2625233908579502e-05\n",
      "loss_item:  2.7421356207923964e-05 - Epoch 23......Step: 3000/3813....... Average Loss for Epoch: 1.2533573072308476e-05\n",
      "Epoch 23/30 Done, Total Loss: 1.2501244428082085e-05\n",
      "Total Time Elapsed: 29.847057300001325 seconds\n",
      "loss_item:  1.0043969268735964e-05 - Epoch 24......Step: 1000/3813....... Average Loss for Epoch: 1.1816447504315874e-05\n",
      "loss_item:  4.947081379214069e-06 - Epoch 24......Step: 2000/3813....... Average Loss for Epoch: 1.2129386442779832e-05\n",
      "loss_item:  6.775536803615978e-06 - Epoch 24......Step: 3000/3813....... Average Loss for Epoch: 1.2127849700618754e-05\n",
      "Epoch 24/30 Done, Total Loss: 1.23039538830065e-05\n",
      "Total Time Elapsed: 29.45084179999685 seconds\n",
      "loss_item:  8.1501311797183e-06 - Epoch 25......Step: 1000/3813....... Average Loss for Epoch: 1.2177934322835426e-05\n",
      "loss_item:  9.56236181082204e-06 - Epoch 25......Step: 2000/3813....... Average Loss for Epoch: 1.2145708852926873e-05\n",
      "loss_item:  5.746574515796965e-06 - Epoch 25......Step: 3000/3813....... Average Loss for Epoch: 1.193893478997173e-05\n",
      "Epoch 25/30 Done, Total Loss: 1.1995753452475128e-05\n",
      "Total Time Elapsed: 30.04695989999891 seconds\n",
      "loss_item:  5.271750524116214e-06 - Epoch 26......Step: 1000/3813....... Average Loss for Epoch: 1.132819780650607e-05\n",
      "loss_item:  6.450721684814198e-06 - Epoch 26......Step: 2000/3813....... Average Loss for Epoch: 1.1339709807998588e-05\n",
      "loss_item:  5.2635632528108545e-06 - Epoch 26......Step: 3000/3813....... Average Loss for Epoch: 1.1371128828765601e-05\n",
      "Epoch 26/30 Done, Total Loss: 1.1776766013302867e-05\n",
      "Total Time Elapsed: 29.692568100002973 seconds\n",
      "loss_item:  5.8475307014305145e-06 - Epoch 27......Step: 1000/3813....... Average Loss for Epoch: 1.2301490369509338e-05\n",
      "loss_item:  5.620323463517707e-06 - Epoch 27......Step: 2000/3813....... Average Loss for Epoch: 1.2162712206645665e-05\n",
      "loss_item:  7.033563633740414e-06 - Epoch 27......Step: 3000/3813....... Average Loss for Epoch: 1.1654353869668435e-05\n",
      "Epoch 27/30 Done, Total Loss: 1.1488799166858831e-05\n",
      "Total Time Elapsed: 29.28443519999928 seconds\n",
      "loss_item:  9.489709555055015e-06 - Epoch 28......Step: 1000/3813....... Average Loss for Epoch: 1.130640376845804e-05\n",
      "loss_item:  5.445302122097928e-06 - Epoch 28......Step: 2000/3813....... Average Loss for Epoch: 1.1303729219434899e-05\n",
      "loss_item:  7.3470855568302795e-06 - Epoch 28......Step: 3000/3813....... Average Loss for Epoch: 1.1426660400123486e-05\n",
      "Epoch 28/30 Done, Total Loss: 1.1492487508905218e-05\n",
      "Total Time Elapsed: 29.30174750000151 seconds\n",
      "loss_item:  7.590369023091625e-06 - Epoch 29......Step: 1000/3813....... Average Loss for Epoch: 1.148976458262041e-05\n",
      "loss_item:  1.6416723155998625e-05 - Epoch 29......Step: 2000/3813....... Average Loss for Epoch: 1.137087331744624e-05\n",
      "loss_item:  1.2213463378429879e-05 - Epoch 29......Step: 3000/3813....... Average Loss for Epoch: 1.1134369656777684e-05\n",
      "Epoch 29/30 Done, Total Loss: 1.1347435129195459e-05\n",
      "Total Time Elapsed: 29.948001799999474 seconds\n",
      "loss_item:  7.111638115020469e-05 - Epoch 30......Step: 1000/3813....... Average Loss for Epoch: 1.1433954999802155e-05\n",
      "loss_item:  8.293063729070127e-06 - Epoch 30......Step: 2000/3813....... Average Loss for Epoch: 1.0909619687140549e-05\n",
      "loss_item:  4.768990947923157e-06 - Epoch 30......Step: 3000/3813....... Average Loss for Epoch: 1.0857364096485374e-05\n",
      "Epoch 30/30 Done, Total Loss: 1.1032492964713376e-05\n",
      "Total Time Elapsed: 29.84028390000094 seconds\n",
      "Total Training Time: 909.7139146000081 seconds\n"
     ]
    }
   ],
   "source": [
    "# model_1_all: 10 epochs lr = 0.0001 8 financial report as timeseries (2years)\n",
    "# model_2_all: 30 epochs lr = 0.0001 8 financial report as timeseries (2years)\n",
    "model_save_path = gru_model_folder + \"model_2_all/\"\n",
    "\n",
    "if not os.path.exists(model_save_path):\n",
    "    os.makedirs(model_save_path)\n",
    "    \n",
    "save_scaler(reports_features_scaler, model_save_path + \"feature_scaler.gz\")\n",
    "save_scaler(stock_features_scaler, model_save_path + \"stock_scaler.gz\")\n",
    "save_scaler(labels_scaler, model_save_path + \"labels_scaler.gz\")\n",
    "\n",
    "lr = 0.0001\n",
    "train_model, avg_loss_list, total_loss_list, epoch_times = train(train_loader, lr, model_save_path, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x17544af1fc8>]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XX_Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34, 85)\n",
      "(34, 85)\n",
      "(35, 85)\n",
      "(0, 85)\n",
      "(0, 85)\n"
     ]
    }
   ],
   "source": [
    "aapl_df = reports_df[reports_df.ticker == 'AAPL']\n",
    "print(aapl_df.shape)\n",
    "msft_df = reports_df[reports_df.ticker == 'MSFT']\n",
    "print(msft_df.shape)\n",
    "a_df = reports_df[reports_df.ticker == 'A']\n",
    "print(a_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: cik, dtype: int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgo_df.cik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filed</th>\n",
       "      <th>c_NetIncomeLoss</th>\n",
       "      <th>c_PaymentsOfDividendsTotal</th>\n",
       "      <th>Assets</th>\n",
       "      <th>Liabilities</th>\n",
       "      <th>gr_netincome_p</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-12-20</th>\n",
       "      <td>2013-12-20</td>\n",
       "      <td>5.520000e+08</td>\n",
       "      <td>198000000.0</td>\n",
       "      <td>3.415000e+09</td>\n",
       "      <td>5.290000e+08</td>\n",
       "      <td>-0.019538</td>\n",
       "      <td>[[0.9237123131752014, 0.6167591214179993, 0.43...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-13</th>\n",
       "      <td>2014-03-13</td>\n",
       "      <td>1.340000e+08</td>\n",
       "      <td>62000000.0</td>\n",
       "      <td>3.472000e+09</td>\n",
       "      <td>4.800000e+08</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>[[0.9213085770606995, 0.5973140001296997, 0.43...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-10</th>\n",
       "      <td>2014-06-10</td>\n",
       "      <td>1.580000e+08</td>\n",
       "      <td>130000000.0</td>\n",
       "      <td>3.671000e+09</td>\n",
       "      <td>5.170000e+08</td>\n",
       "      <td>0.398230</td>\n",
       "      <td>[[0.9278937578201294, 0.6536733508110046, 0.43...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-12</th>\n",
       "      <td>2014-09-12</td>\n",
       "      <td>-1.640000e+08</td>\n",
       "      <td>203000000.0</td>\n",
       "      <td>1.026200e+10</td>\n",
       "      <td>7.164000e+09</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>[[0.9317957758903503, 0.6922041773796082, 0.43...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-29</th>\n",
       "      <td>2014-12-29</td>\n",
       "      <td>2.630000e+08</td>\n",
       "      <td>284000000.0</td>\n",
       "      <td>1.049100e+10</td>\n",
       "      <td>7.248000e+09</td>\n",
       "      <td>-0.523551</td>\n",
       "      <td>[[0.9460984468460083, 0.8811360597610474, 0.42...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-11</th>\n",
       "      <td>2015-03-11</td>\n",
       "      <td>3.510000e+08</td>\n",
       "      <td>89000000.0</td>\n",
       "      <td>1.069700e+10</td>\n",
       "      <td>7.069000e+09</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>[[0.9394939541816711, 0.7827935814857483, 0.43...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-10</th>\n",
       "      <td>2015-06-10</td>\n",
       "      <td>3.440000e+08</td>\n",
       "      <td>188000000.0</td>\n",
       "      <td>1.053200e+10</td>\n",
       "      <td>6.471000e+09</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>[[0.9228112697601318, 0.6093282103538513, 0.43...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-10</th>\n",
       "      <td>2015-09-10</td>\n",
       "      <td>2.400000e+08</td>\n",
       "      <td>292000000.0</td>\n",
       "      <td>9.988000e+09</td>\n",
       "      <td>5.707000e+09</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>[[0.9224422574043274, 0.6063345670700073, 0.43...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-17</th>\n",
       "      <td>2015-12-17</td>\n",
       "      <td>1.364000e+09</td>\n",
       "      <td>408000000.0</td>\n",
       "      <td>1.059200e+10</td>\n",
       "      <td>5.878000e+09</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>[[0.9347319602966309, 0.724234938621521, 0.430...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                filed  c_NetIncomeLoss  c_PaymentsOfDividendsTotal  \\\n",
       "i_date                                                               \n",
       "2013-12-20 2013-12-20     5.520000e+08                 198000000.0   \n",
       "2014-03-13 2014-03-13     1.340000e+08                  62000000.0   \n",
       "2014-06-10 2014-06-10     1.580000e+08                 130000000.0   \n",
       "2014-09-12 2014-09-12    -1.640000e+08                 203000000.0   \n",
       "2014-12-29 2014-12-29     2.630000e+08                 284000000.0   \n",
       "2015-03-11 2015-03-11     3.510000e+08                  89000000.0   \n",
       "2015-06-10 2015-06-10     3.440000e+08                 188000000.0   \n",
       "2015-09-10 2015-09-10     2.400000e+08                 292000000.0   \n",
       "2015-12-17 2015-12-17     1.364000e+09                 408000000.0   \n",
       "\n",
       "                  Assets   Liabilities  gr_netincome_p  \\\n",
       "i_date                                                   \n",
       "2013-12-20  3.415000e+09  5.290000e+08       -0.019538   \n",
       "2014-03-13  3.472000e+09  4.800000e+08        0.072000   \n",
       "2014-06-10  3.671000e+09  5.170000e+08        0.398230   \n",
       "2014-09-12  1.026200e+10  7.164000e+09       -0.750000   \n",
       "2014-12-29  1.049100e+10  7.248000e+09       -0.523551   \n",
       "2015-03-11  1.069700e+10  7.069000e+09        0.750000   \n",
       "2015-06-10  1.053200e+10  6.471000e+09        0.750000   \n",
       "2015-09-10  9.988000e+09  5.707000e+09       -0.000000   \n",
       "2015-12-17  1.059200e+10  5.878000e+09        0.750000   \n",
       "\n",
       "                                                     features  \n",
       "i_date                                                         \n",
       "2013-12-20  [[0.9237123131752014, 0.6167591214179993, 0.43...  \n",
       "2014-03-13  [[0.9213085770606995, 0.5973140001296997, 0.43...  \n",
       "2014-06-10  [[0.9278937578201294, 0.6536733508110046, 0.43...  \n",
       "2014-09-12  [[0.9317957758903503, 0.6922041773796082, 0.43...  \n",
       "2014-12-29  [[0.9460984468460083, 0.8811360597610474, 0.42...  \n",
       "2015-03-11  [[0.9394939541816711, 0.7827935814857483, 0.43...  \n",
       "2015-06-10  [[0.9228112697601318, 0.6093282103538513, 0.43...  \n",
       "2015-09-10  [[0.9224422574043274, 0.6063345670700073, 0.43...  \n",
       "2015-12-17  [[0.9347319602966309, 0.724234938621521, 0.430...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_col = create_sequence_series(avgo_df)\n",
    "merge_report_data_with_sequence_series(avgo_df, seq_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(34, 46)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_df_features = reports_features_scaler.transform(reports_df[features_reports]).astype(np.float32)\n",
    "print(np_df_features.dtype)\n",
    "np_df_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 8, 46)\n"
     ]
    }
   ],
   "source": [
    "lookback_size = 8\n",
    "number_of_features = len(features_reports)\n",
    "number_of_rows = len(np_df_features)\n",
    "\n",
    "number_of_sequences = number_of_rows - lookback + 1\n",
    "\n",
    "inputs = np.zeros((number_of_sequences, lookback, number_of_features))\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 8, 46)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, number_of_sequences):\n",
    "    inputs[i] = np_df_features[i : i + lookback]\n",
    "    \n",
    "print (inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 368)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_input = inputs.reshape(-1, lookback_size * number_of_features)\n",
    "flat_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27,)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_col = pd.Series(flat_input.tolist(), name='features').apply(lambda field: np.array(field).reshape(lookback, number_of_features))\n",
    "features_col.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27,)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_col = reports_df.filed[lookback - 1:].reset_index(drop=True)\n",
    "date_col.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filed</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-28</td>\n",
       "      <td>[[0.7868078389231806, 0.6630857047421554, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-04-24</td>\n",
       "      <td>[[0.776629286748127, 0.6496306048392506, 0.006...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-07-23</td>\n",
       "      <td>[[0.7078445773271538, 0.5637078809160074, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-10-27</td>\n",
       "      <td>[[0.7519515180156731, 0.6178265461170032, 0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>[[0.9394095609049016, 0.8921025625874786, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-04-28</td>\n",
       "      <td>[[0.9999999999999999, 1.0000000000000002, 0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-07-22</td>\n",
       "      <td>[[0.8640773461987664, 0.7722151793702814, 0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-10-28</td>\n",
       "      <td>[[0.706357307915412, 0.5619409510885764, 0.101...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016-01-27</td>\n",
       "      <td>[[0.8280166003209201, 0.7196892650544637, 0.09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016-04-27</td>\n",
       "      <td>[[0.6832097720805139, 0.5349050497826269, 0.13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2016-07-27</td>\n",
       "      <td>[[0.15560741722514743, 0.08948040885986486, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2016-10-26</td>\n",
       "      <td>[[0.24839733307930484, 0.14983539491984188, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>[[0.286053600277351, 0.17604980611694376, 0.19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017-05-03</td>\n",
       "      <td>[[0.16786862516621257, 0.09713045457472846, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017-08-02</td>\n",
       "      <td>[[0.20696405652990574, 0.12217016838681372, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017-11-03</td>\n",
       "      <td>[[0.0, 0.0, 0.2875643529956204, 0.552155937148...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-02-02</td>\n",
       "      <td>[[0.46997297945833716, 0.32104637524425494, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-05-02</td>\n",
       "      <td>[[0.5062950894702718, 0.35353586849393337, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>[[0.555976756660519, 0.4003841163019357, 0.362...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-11-05</td>\n",
       "      <td>[[0.3952436242401163, 0.25845048567742435, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2019-01-30</td>\n",
       "      <td>[[0.5992634017343288, 0.44366087514577757, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>[[0.5967442594076062, 0.44107588811720344, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>[[0.4607262624858036, 0.3129994444979607, 0.46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>[[0.41461524422337115, 0.2741569961080046, 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>[[0.6686122881146315, 0.5182920504228983, 0.49...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>[[0.5009447778913816, 0.34865981897525633, 0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2020-07-31</td>\n",
       "      <td>[[0.23292321194541446, 0.1393627890644007, 0.6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        filed                                           features\n",
       "0  2014-01-28  [[0.7868078389231806, 0.6630857047421554, 0.01...\n",
       "1  2014-04-24  [[0.776629286748127, 0.6496306048392506, 0.006...\n",
       "2  2014-07-23  [[0.7078445773271538, 0.5637078809160074, 0.01...\n",
       "3  2014-10-27  [[0.7519515180156731, 0.6178265461170032, 0.03...\n",
       "4  2015-01-28  [[0.9394095609049016, 0.8921025625874786, 0.0,...\n",
       "5  2015-04-28  [[0.9999999999999999, 1.0000000000000002, 0.06...\n",
       "6  2015-07-22  [[0.8640773461987664, 0.7722151793702814, 0.08...\n",
       "7  2015-10-28  [[0.706357307915412, 0.5619409510885764, 0.101...\n",
       "8  2016-01-27  [[0.8280166003209201, 0.7196892650544637, 0.09...\n",
       "9  2016-04-27  [[0.6832097720805139, 0.5349050497826269, 0.13...\n",
       "10 2016-07-27  [[0.15560741722514743, 0.08948040885986486, 0....\n",
       "11 2016-10-26  [[0.24839733307930484, 0.14983539491984188, 0....\n",
       "12 2017-02-01  [[0.286053600277351, 0.17604980611694376, 0.19...\n",
       "13 2017-05-03  [[0.16786862516621257, 0.09713045457472846, 0....\n",
       "14 2017-08-02  [[0.20696405652990574, 0.12217016838681372, 0....\n",
       "15 2017-11-03  [[0.0, 0.0, 0.2875643529956204, 0.552155937148...\n",
       "16 2018-02-02  [[0.46997297945833716, 0.32104637524425494, 0....\n",
       "17 2018-05-02  [[0.5062950894702718, 0.35353586849393337, 0.3...\n",
       "18 2018-08-01  [[0.555976756660519, 0.4003841163019357, 0.362...\n",
       "19 2018-11-05  [[0.3952436242401163, 0.25845048567742435, 0.3...\n",
       "20 2019-01-30  [[0.5992634017343288, 0.44366087514577757, 0.3...\n",
       "21 2019-05-01  [[0.5967442594076062, 0.44107588811720344, 0.3...\n",
       "22 2019-07-31  [[0.4607262624858036, 0.3129994444979607, 0.46...\n",
       "23 2019-10-31  [[0.41461524422337115, 0.2741569961080046, 0.4...\n",
       "24 2020-01-29  [[0.6686122881146315, 0.5182920504228983, 0.49...\n",
       "25 2020-05-01  [[0.5009447778913816, 0.34865981897525633, 0.5...\n",
       "26 2020-07-31  [[0.23292321194541446, 0.1393627890644007, 0.6..."
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df_combined = pd.concat([date_col, features_col], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78680784, 0.6630857 , 0.0119307 , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.77662929, 0.6496306 , 0.00691177, ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.70784458, 0.56370788, 0.01764061, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.79937715, 0.67998255, 0.80159741, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.70795353, 0.56383747, 0.89674084, ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.68206885, 0.53359463, 1.        , ..., 0.        , 1.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 46)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.DataFrame(np_df_features)\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-04-25</td>\n",
       "      <td>0.786808</td>\n",
       "      <td>0.663086</td>\n",
       "      <td>0.011931</td>\n",
       "      <td>0.035571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-07-25</td>\n",
       "      <td>0.776629</td>\n",
       "      <td>0.649631</td>\n",
       "      <td>0.006912</td>\n",
       "      <td>0.020817</td>\n",
       "      <td>0.565625</td>\n",
       "      <td>0.650950</td>\n",
       "      <td>0.603353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.997016</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>0.707845</td>\n",
       "      <td>0.563708</td>\n",
       "      <td>0.017641</td>\n",
       "      <td>0.051999</td>\n",
       "      <td>0.666490</td>\n",
       "      <td>0.777428</td>\n",
       "      <td>0.733998</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968144</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-24</td>\n",
       "      <td>0.751952</td>\n",
       "      <td>0.617827</td>\n",
       "      <td>0.034704</td>\n",
       "      <td>0.098949</td>\n",
       "      <td>0.167814</td>\n",
       "      <td>0.568224</td>\n",
       "      <td>0.496380</td>\n",
       "      <td>0.622115</td>\n",
       "      <td>0.856895</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-04-24</td>\n",
       "      <td>0.939410</td>\n",
       "      <td>0.892103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059409</td>\n",
       "      <td>0.412637</td>\n",
       "      <td>0.310148</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.859870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-07-24</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.061922</td>\n",
       "      <td>0.167797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.258043</td>\n",
       "      <td>0.100323</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.849345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.418530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013-10-30</td>\n",
       "      <td>0.864077</td>\n",
       "      <td>0.772215</td>\n",
       "      <td>0.080637</td>\n",
       "      <td>0.211303</td>\n",
       "      <td>0.071725</td>\n",
       "      <td>0.405263</td>\n",
       "      <td>0.290171</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.777455</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.427019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014-01-28</td>\n",
       "      <td>0.706357</td>\n",
       "      <td>0.561941</td>\n",
       "      <td>0.101279</td>\n",
       "      <td>0.256077</td>\n",
       "      <td>0.100912</td>\n",
       "      <td>0.498011</td>\n",
       "      <td>0.381372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.751768</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.311000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2014-04-24</td>\n",
       "      <td>0.828017</td>\n",
       "      <td>0.719689</td>\n",
       "      <td>0.093698</td>\n",
       "      <td>0.240003</td>\n",
       "      <td>0.232948</td>\n",
       "      <td>0.467587</td>\n",
       "      <td>0.354666</td>\n",
       "      <td>0.848017</td>\n",
       "      <td>0.446036</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.364034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2014-07-23</td>\n",
       "      <td>0.683210</td>\n",
       "      <td>0.534905</td>\n",
       "      <td>0.136333</td>\n",
       "      <td>0.325314</td>\n",
       "      <td>0.237416</td>\n",
       "      <td>0.337811</td>\n",
       "      <td>0.203833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.656839</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.435719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2014-10-27</td>\n",
       "      <td>0.155607</td>\n",
       "      <td>0.089480</td>\n",
       "      <td>0.217090</td>\n",
       "      <td>0.458575</td>\n",
       "      <td>0.163467</td>\n",
       "      <td>0.408232</td>\n",
       "      <td>0.285186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.550421</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.503138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>0.248397</td>\n",
       "      <td>0.149835</td>\n",
       "      <td>0.232382</td>\n",
       "      <td>0.480440</td>\n",
       "      <td>0.285318</td>\n",
       "      <td>0.620497</td>\n",
       "      <td>0.511498</td>\n",
       "      <td>0.732363</td>\n",
       "      <td>0.847544</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2015-04-28</td>\n",
       "      <td>0.286054</td>\n",
       "      <td>0.176050</td>\n",
       "      <td>0.198894</td>\n",
       "      <td>0.431290</td>\n",
       "      <td>0.372089</td>\n",
       "      <td>0.564704</td>\n",
       "      <td>0.443041</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.876484</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.961304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2015-07-22</td>\n",
       "      <td>0.167869</td>\n",
       "      <td>0.097130</td>\n",
       "      <td>0.249273</td>\n",
       "      <td>0.503534</td>\n",
       "      <td>0.267000</td>\n",
       "      <td>0.389583</td>\n",
       "      <td>0.277159</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.873418</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.962243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2015-10-28</td>\n",
       "      <td>0.206964</td>\n",
       "      <td>0.122170</td>\n",
       "      <td>0.337421</td>\n",
       "      <td>0.608692</td>\n",
       "      <td>0.303606</td>\n",
       "      <td>0.506796</td>\n",
       "      <td>0.394610</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.838631</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.832222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016-01-27</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287564</td>\n",
       "      <td>0.552156</td>\n",
       "      <td>0.307214</td>\n",
       "      <td>0.584318</td>\n",
       "      <td>0.514945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.699231</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2016-04-27</td>\n",
       "      <td>0.469973</td>\n",
       "      <td>0.321046</td>\n",
       "      <td>0.305697</td>\n",
       "      <td>0.573541</td>\n",
       "      <td>0.241066</td>\n",
       "      <td>0.348894</td>\n",
       "      <td>0.212845</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909675</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2016-07-27</td>\n",
       "      <td>0.506295</td>\n",
       "      <td>0.353536</td>\n",
       "      <td>0.331090</td>\n",
       "      <td>0.601895</td>\n",
       "      <td>0.109718</td>\n",
       "      <td>0.134933</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.793928</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2016-10-26</td>\n",
       "      <td>0.555977</td>\n",
       "      <td>0.400384</td>\n",
       "      <td>0.362667</td>\n",
       "      <td>0.634790</td>\n",
       "      <td>0.209922</td>\n",
       "      <td>0.358419</td>\n",
       "      <td>0.247191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.773263</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>0.395244</td>\n",
       "      <td>0.258450</td>\n",
       "      <td>0.360283</td>\n",
       "      <td>0.632392</td>\n",
       "      <td>0.156405</td>\n",
       "      <td>0.469503</td>\n",
       "      <td>0.393601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.679198</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.334134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2017-05-03</td>\n",
       "      <td>0.599263</td>\n",
       "      <td>0.443661</td>\n",
       "      <td>0.358159</td>\n",
       "      <td>0.630244</td>\n",
       "      <td>0.195771</td>\n",
       "      <td>0.291866</td>\n",
       "      <td>0.217294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.786275</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.371253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2017-08-02</td>\n",
       "      <td>0.596744</td>\n",
       "      <td>0.441076</td>\n",
       "      <td>0.395942</td>\n",
       "      <td>0.666906</td>\n",
       "      <td>0.156326</td>\n",
       "      <td>0.126941</td>\n",
       "      <td>0.070381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.796200</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2017-11-03</td>\n",
       "      <td>0.460726</td>\n",
       "      <td>0.312999</td>\n",
       "      <td>0.461417</td>\n",
       "      <td>0.723520</td>\n",
       "      <td>0.152215</td>\n",
       "      <td>0.298045</td>\n",
       "      <td>0.238805</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800215</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.308952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018-02-02</td>\n",
       "      <td>0.414615</td>\n",
       "      <td>0.274157</td>\n",
       "      <td>0.495837</td>\n",
       "      <td>0.750255</td>\n",
       "      <td>0.146371</td>\n",
       "      <td>0.466383</td>\n",
       "      <td>0.383919</td>\n",
       "      <td>0.595233</td>\n",
       "      <td>0.805576</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.414382</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2018-05-02</td>\n",
       "      <td>0.668612</td>\n",
       "      <td>0.518292</td>\n",
       "      <td>0.494127</td>\n",
       "      <td>0.748972</td>\n",
       "      <td>0.137059</td>\n",
       "      <td>0.255188</td>\n",
       "      <td>0.373502</td>\n",
       "      <td>0.450203</td>\n",
       "      <td>0.445931</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.482517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>0.500945</td>\n",
       "      <td>0.348660</td>\n",
       "      <td>0.541991</td>\n",
       "      <td>0.783298</td>\n",
       "      <td>0.139708</td>\n",
       "      <td>0.124917</td>\n",
       "      <td>0.286204</td>\n",
       "      <td>0.663819</td>\n",
       "      <td>0.200562</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.629409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2018-11-05</td>\n",
       "      <td>0.232923</td>\n",
       "      <td>0.139363</td>\n",
       "      <td>0.669134</td>\n",
       "      <td>0.860674</td>\n",
       "      <td>0.140205</td>\n",
       "      <td>0.294316</td>\n",
       "      <td>0.356260</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.195422</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.642154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073851</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2019-01-30</td>\n",
       "      <td>0.492399</td>\n",
       "      <td>0.340938</td>\n",
       "      <td>0.586748</td>\n",
       "      <td>0.812626</td>\n",
       "      <td>0.106711</td>\n",
       "      <td>0.350290</td>\n",
       "      <td>0.468781</td>\n",
       "      <td>0.427688</td>\n",
       "      <td>0.632096</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.278677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>0.511000</td>\n",
       "      <td>0.357851</td>\n",
       "      <td>0.607287</td>\n",
       "      <td>0.825282</td>\n",
       "      <td>0.070602</td>\n",
       "      <td>0.093774</td>\n",
       "      <td>0.135298</td>\n",
       "      <td>0.514792</td>\n",
       "      <td>0.192000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>0.716236</td>\n",
       "      <td>0.573746</td>\n",
       "      <td>0.644579</td>\n",
       "      <td>0.847085</td>\n",
       "      <td>0.068477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023193</td>\n",
       "      <td>0.459057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>0.749092</td>\n",
       "      <td>0.614214</td>\n",
       "      <td>0.780106</td>\n",
       "      <td>0.915515</td>\n",
       "      <td>0.090128</td>\n",
       "      <td>0.175137</td>\n",
       "      <td>0.251750</td>\n",
       "      <td>0.523620</td>\n",
       "      <td>0.071801</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.216096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029682</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>0.799377</td>\n",
       "      <td>0.679983</td>\n",
       "      <td>0.801597</td>\n",
       "      <td>0.925044</td>\n",
       "      <td>0.141261</td>\n",
       "      <td>0.359080</td>\n",
       "      <td>0.516477</td>\n",
       "      <td>0.095642</td>\n",
       "      <td>0.407478</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.543793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>0.707954</td>\n",
       "      <td>0.563837</td>\n",
       "      <td>0.896741</td>\n",
       "      <td>0.963672</td>\n",
       "      <td>0.141940</td>\n",
       "      <td>0.033009</td>\n",
       "      <td>0.078704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.249688</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.563300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2020-07-31</td>\n",
       "      <td>0.682069</td>\n",
       "      <td>0.533595</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.107431</td>\n",
       "      <td>0.026948</td>\n",
       "      <td>0.039895</td>\n",
       "      <td>0.069485</td>\n",
       "      <td>0.227398</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.638195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0  2012-04-25  0.786808  0.663086  0.011931  0.035571  1.000000  1.000000   \n",
       "1  2012-07-25  0.776629  0.649631  0.006912  0.020817  0.565625  0.650950   \n",
       "2  2012-10-31  0.707845  0.563708  0.017641  0.051999  0.666490  0.777428   \n",
       "3  2013-01-24  0.751952  0.617827  0.034704  0.098949  0.167814  0.568224   \n",
       "4  2013-04-24  0.939410  0.892103  0.000000  0.000000  0.059409  0.412637   \n",
       "5  2013-07-24  1.000000  1.000000  0.061922  0.167797  0.000000  0.258043   \n",
       "6  2013-10-30  0.864077  0.772215  0.080637  0.211303  0.071725  0.405263   \n",
       "7  2014-01-28  0.706357  0.561941  0.101279  0.256077  0.100912  0.498011   \n",
       "8  2014-04-24  0.828017  0.719689  0.093698  0.240003  0.232948  0.467587   \n",
       "9  2014-07-23  0.683210  0.534905  0.136333  0.325314  0.237416  0.337811   \n",
       "10 2014-10-27  0.155607  0.089480  0.217090  0.458575  0.163467  0.408232   \n",
       "11 2015-01-28  0.248397  0.149835  0.232382  0.480440  0.285318  0.620497   \n",
       "12 2015-04-28  0.286054  0.176050  0.198894  0.431290  0.372089  0.564704   \n",
       "13 2015-07-22  0.167869  0.097130  0.249273  0.503534  0.267000  0.389583   \n",
       "14 2015-10-28  0.206964  0.122170  0.337421  0.608692  0.303606  0.506796   \n",
       "15 2016-01-27  0.000000  0.000000  0.287564  0.552156  0.307214  0.584318   \n",
       "16 2016-04-27  0.469973  0.321046  0.305697  0.573541  0.241066  0.348894   \n",
       "17 2016-07-27  0.506295  0.353536  0.331090  0.601895  0.109718  0.134933   \n",
       "18 2016-10-26  0.555977  0.400384  0.362667  0.634790  0.209922  0.358419   \n",
       "19 2017-02-01  0.395244  0.258450  0.360283  0.632392  0.156405  0.469503   \n",
       "20 2017-05-03  0.599263  0.443661  0.358159  0.630244  0.195771  0.291866   \n",
       "21 2017-08-02  0.596744  0.441076  0.395942  0.666906  0.156326  0.126941   \n",
       "22 2017-11-03  0.460726  0.312999  0.461417  0.723520  0.152215  0.298045   \n",
       "23 2018-02-02  0.414615  0.274157  0.495837  0.750255  0.146371  0.466383   \n",
       "24 2018-05-02  0.668612  0.518292  0.494127  0.748972  0.137059  0.255188   \n",
       "25 2018-08-01  0.500945  0.348660  0.541991  0.783298  0.139708  0.124917   \n",
       "26 2018-11-05  0.232923  0.139363  0.669134  0.860674  0.140205  0.294316   \n",
       "27 2019-01-30  0.492399  0.340938  0.586748  0.812626  0.106711  0.350290   \n",
       "28 2019-05-01  0.511000  0.357851  0.607287  0.825282  0.070602  0.093774   \n",
       "29 2019-07-31  0.716236  0.573746  0.644579  0.847085  0.068477  0.000000   \n",
       "30 2019-10-31  0.749092  0.614214  0.780106  0.915515  0.090128  0.175137   \n",
       "31 2020-01-29  0.799377  0.679983  0.801597  0.925044  0.141261  0.359080   \n",
       "32 2020-05-01  0.707954  0.563837  0.896741  0.963672  0.141940  0.033009   \n",
       "33 2020-07-31  0.682069  0.533595  1.000000  1.000000  0.107431  0.026948   \n",
       "\n",
       "          7         8         9   ...   37   38        39   40        41   42  \\\n",
       "0   1.000000  1.000000  1.000000  ...  1.0  0.0  0.353778  0.0  0.000000  0.0   \n",
       "1   0.603353  0.000000  0.997016  ...  1.0  0.0  0.353778  0.0  0.000000  0.0   \n",
       "2   0.733998  1.000000  0.968144  ...  1.0  0.0  0.353778  0.0  0.000000  1.0   \n",
       "3   0.496380  0.622115  0.856895  ...  1.0  0.0  0.353778  0.0  0.000000  0.0   \n",
       "4   0.310148  1.000000  0.859870  ...  0.0  0.0  0.538709  0.0  0.000000  0.0   \n",
       "5   0.100323  1.000000  0.849345  ...  0.0  0.0  0.418530  0.0  0.000000  0.0   \n",
       "6   0.290171  1.000000  0.777455  ...  1.0  0.0  0.427019  0.0  0.000000  1.0   \n",
       "7   0.381372  0.000000  0.751768  ...  1.0  0.0  0.311000  0.0  0.000000  0.0   \n",
       "8   0.354666  0.848017  0.446036  ...  1.0  0.0  0.364034  0.0  0.000000  0.0   \n",
       "9   0.203833  0.000000  0.656839  ...  1.0  0.0  0.435719  0.0  0.000000  0.0   \n",
       "10  0.285186  0.000000  0.550421  ...  1.0  0.0  0.503138  0.0  0.000000  1.0   \n",
       "11  0.511498  0.732363  0.847544  ...  1.0  0.0  1.000000  0.0  0.000000  0.0   \n",
       "12  0.443041  1.000000  0.876484  ...  1.0  0.0  0.961304  0.0  0.000000  0.0   \n",
       "13  0.277159  1.000000  0.873418  ...  1.0  0.0  0.962243  0.0  0.000000  0.0   \n",
       "14  0.394610  1.000000  0.838631  ...  1.0  0.0  0.832222  0.0  0.000000  1.0   \n",
       "15  0.514945  0.000000  0.699231  ...  1.0  0.0  0.107750  0.0  0.000000  0.0   \n",
       "16  0.212845  1.000000  0.909675  ...  1.0  0.0  0.008881  0.0  0.000000  0.0   \n",
       "17  0.000000  0.000000  0.793928  ...  1.0  0.0  0.000000  0.0  0.000000  0.0   \n",
       "18  0.247191  0.000000  0.773263  ...  1.0  0.0  0.101902  0.0  0.000000  1.0   \n",
       "19  0.393601  0.000000  0.679198  ...  1.0  0.0  0.334134  0.0  0.000000  0.0   \n",
       "20  0.217294  0.000000  0.786275  ...  1.0  0.0  0.371253  0.0  0.000000  0.0   \n",
       "21  0.070381  0.000000  0.796200  ...  1.0  0.0  0.306942  0.0  1.000000  0.0   \n",
       "22  0.238805  0.000000  0.800215  ...  1.0  0.0  0.308952  0.0  1.000000  1.0   \n",
       "23  0.383919  0.595233  0.805576  ...  1.0  0.0  0.414382  0.0  1.000000  0.0   \n",
       "24  0.373502  0.450203  0.445931  ...  1.0  0.0  0.482517  0.0  1.000000  0.0   \n",
       "25  0.286204  0.663819  0.200562  ...  1.0  0.0  0.629409  0.0  0.071902  0.0   \n",
       "26  0.356260  1.000000  0.195422  ...  1.0  0.0  0.642154  0.0  0.073851  1.0   \n",
       "27  0.468781  0.427688  0.632096  ...  1.0  0.0  0.278677  0.0  0.068583  0.0   \n",
       "28  0.135298  0.514792  0.192000  ...  1.0  0.0  0.183503  0.0  0.073824  0.0   \n",
       "29  0.023193  0.459057  0.000000  ...  1.0  0.0  0.160822  0.0  0.044981  0.0   \n",
       "30  0.251750  0.523620  0.071801  ...  1.0  0.0  0.216096  0.0  0.029682  1.0   \n",
       "31  0.516477  0.095642  0.407478  ...  1.0  0.0  0.543793  0.0  0.000000  0.0   \n",
       "32  0.078704  0.000000  0.249688  ...  1.0  0.0  0.563300  0.0  0.000000  0.0   \n",
       "33  0.039895  0.069485  0.227398  ...  1.0  0.0  0.638195  0.0  0.000000  0.0   \n",
       "\n",
       "     43   44   45   46  \n",
       "0   0.0  1.0  0.0  0.0  \n",
       "1   0.0  0.0  1.0  0.0  \n",
       "2   0.0  0.0  0.0  0.0  \n",
       "3   1.0  0.0  0.0  0.0  \n",
       "4   0.0  1.0  0.0  0.0  \n",
       "5   0.0  0.0  1.0  0.0  \n",
       "6   0.0  0.0  0.0  0.0  \n",
       "7   1.0  0.0  0.0  0.0  \n",
       "8   0.0  1.0  0.0  0.0  \n",
       "9   0.0  0.0  1.0  0.0  \n",
       "10  0.0  0.0  0.0  0.0  \n",
       "11  1.0  0.0  0.0  0.0  \n",
       "12  0.0  1.0  0.0  0.0  \n",
       "13  0.0  0.0  1.0  0.0  \n",
       "14  0.0  0.0  0.0  0.0  \n",
       "15  1.0  0.0  0.0  0.0  \n",
       "16  0.0  1.0  0.0  0.0  \n",
       "17  0.0  0.0  1.0  0.0  \n",
       "18  0.0  0.0  0.0  0.0  \n",
       "19  1.0  0.0  0.0  0.0  \n",
       "20  0.0  1.0  0.0  0.0  \n",
       "21  0.0  0.0  1.0  0.0  \n",
       "22  0.0  0.0  0.0  0.0  \n",
       "23  1.0  0.0  0.0  0.0  \n",
       "24  0.0  1.0  0.0  0.0  \n",
       "25  0.0  0.0  1.0  0.0  \n",
       "26  0.0  0.0  0.0  0.0  \n",
       "27  1.0  0.0  0.0  0.0  \n",
       "28  0.0  1.0  0.0  0.0  \n",
       "29  0.0  0.0  1.0  0.0  \n",
       "30  0.0  0.0  0.0  0.0  \n",
       "31  1.0  0.0  0.0  0.0  \n",
       "32  0.0  1.0  0.0  0.0  \n",
       "33  0.0  0.0  1.0  0.0  \n",
       "\n",
       "[34 rows x 47 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filed_col = reports_df.filed.reset_index(drop=True)\n",
    "print(filed_col.shape)\n",
    "result = pd.concat([filed_col, new_df], axis=1, ignore_index=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-04-25</td>\n",
       "      <td>0.786808</td>\n",
       "      <td>0.663086</td>\n",
       "      <td>0.011931</td>\n",
       "      <td>0.035571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-07-25</td>\n",
       "      <td>0.776629</td>\n",
       "      <td>0.649631</td>\n",
       "      <td>0.006912</td>\n",
       "      <td>0.020817</td>\n",
       "      <td>0.565625</td>\n",
       "      <td>0.650950</td>\n",
       "      <td>0.603353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.997016</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>0.707845</td>\n",
       "      <td>0.563708</td>\n",
       "      <td>0.017641</td>\n",
       "      <td>0.051999</td>\n",
       "      <td>0.666490</td>\n",
       "      <td>0.777428</td>\n",
       "      <td>0.733998</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968144</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-24</td>\n",
       "      <td>0.751952</td>\n",
       "      <td>0.617827</td>\n",
       "      <td>0.034704</td>\n",
       "      <td>0.098949</td>\n",
       "      <td>0.167814</td>\n",
       "      <td>0.568224</td>\n",
       "      <td>0.496380</td>\n",
       "      <td>0.622115</td>\n",
       "      <td>0.856895</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-04-24</td>\n",
       "      <td>0.939410</td>\n",
       "      <td>0.892103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059409</td>\n",
       "      <td>0.412637</td>\n",
       "      <td>0.310148</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.859870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-07-24</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.061922</td>\n",
       "      <td>0.167797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.258043</td>\n",
       "      <td>0.100323</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.849345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.418530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013-10-30</td>\n",
       "      <td>0.864077</td>\n",
       "      <td>0.772215</td>\n",
       "      <td>0.080637</td>\n",
       "      <td>0.211303</td>\n",
       "      <td>0.071725</td>\n",
       "      <td>0.405263</td>\n",
       "      <td>0.290171</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.777455</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.427019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014-01-28</td>\n",
       "      <td>0.706357</td>\n",
       "      <td>0.561941</td>\n",
       "      <td>0.101279</td>\n",
       "      <td>0.256077</td>\n",
       "      <td>0.100912</td>\n",
       "      <td>0.498011</td>\n",
       "      <td>0.381372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.751768</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.311000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2014-04-24</td>\n",
       "      <td>0.828017</td>\n",
       "      <td>0.719689</td>\n",
       "      <td>0.093698</td>\n",
       "      <td>0.240003</td>\n",
       "      <td>0.232948</td>\n",
       "      <td>0.467587</td>\n",
       "      <td>0.354666</td>\n",
       "      <td>0.848017</td>\n",
       "      <td>0.446036</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.364034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2014-07-23</td>\n",
       "      <td>0.683210</td>\n",
       "      <td>0.534905</td>\n",
       "      <td>0.136333</td>\n",
       "      <td>0.325314</td>\n",
       "      <td>0.237416</td>\n",
       "      <td>0.337811</td>\n",
       "      <td>0.203833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.656839</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.435719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2014-10-27</td>\n",
       "      <td>0.155607</td>\n",
       "      <td>0.089480</td>\n",
       "      <td>0.217090</td>\n",
       "      <td>0.458575</td>\n",
       "      <td>0.163467</td>\n",
       "      <td>0.408232</td>\n",
       "      <td>0.285186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.550421</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.503138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>0.248397</td>\n",
       "      <td>0.149835</td>\n",
       "      <td>0.232382</td>\n",
       "      <td>0.480440</td>\n",
       "      <td>0.285318</td>\n",
       "      <td>0.620497</td>\n",
       "      <td>0.511498</td>\n",
       "      <td>0.732363</td>\n",
       "      <td>0.847544</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2015-04-28</td>\n",
       "      <td>0.286054</td>\n",
       "      <td>0.176050</td>\n",
       "      <td>0.198894</td>\n",
       "      <td>0.431290</td>\n",
       "      <td>0.372089</td>\n",
       "      <td>0.564704</td>\n",
       "      <td>0.443041</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.876484</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.961304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2015-07-22</td>\n",
       "      <td>0.167869</td>\n",
       "      <td>0.097130</td>\n",
       "      <td>0.249273</td>\n",
       "      <td>0.503534</td>\n",
       "      <td>0.267000</td>\n",
       "      <td>0.389583</td>\n",
       "      <td>0.277159</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.873418</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.962243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2015-10-28</td>\n",
       "      <td>0.206964</td>\n",
       "      <td>0.122170</td>\n",
       "      <td>0.337421</td>\n",
       "      <td>0.608692</td>\n",
       "      <td>0.303606</td>\n",
       "      <td>0.506796</td>\n",
       "      <td>0.394610</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.838631</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.832222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016-01-27</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287564</td>\n",
       "      <td>0.552156</td>\n",
       "      <td>0.307214</td>\n",
       "      <td>0.584318</td>\n",
       "      <td>0.514945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.699231</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2016-04-27</td>\n",
       "      <td>0.469973</td>\n",
       "      <td>0.321046</td>\n",
       "      <td>0.305697</td>\n",
       "      <td>0.573541</td>\n",
       "      <td>0.241066</td>\n",
       "      <td>0.348894</td>\n",
       "      <td>0.212845</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909675</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2016-07-27</td>\n",
       "      <td>0.506295</td>\n",
       "      <td>0.353536</td>\n",
       "      <td>0.331090</td>\n",
       "      <td>0.601895</td>\n",
       "      <td>0.109718</td>\n",
       "      <td>0.134933</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.793928</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2016-10-26</td>\n",
       "      <td>0.555977</td>\n",
       "      <td>0.400384</td>\n",
       "      <td>0.362667</td>\n",
       "      <td>0.634790</td>\n",
       "      <td>0.209922</td>\n",
       "      <td>0.358419</td>\n",
       "      <td>0.247191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.773263</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>0.395244</td>\n",
       "      <td>0.258450</td>\n",
       "      <td>0.360283</td>\n",
       "      <td>0.632392</td>\n",
       "      <td>0.156405</td>\n",
       "      <td>0.469503</td>\n",
       "      <td>0.393601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.679198</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.334134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2017-05-03</td>\n",
       "      <td>0.599263</td>\n",
       "      <td>0.443661</td>\n",
       "      <td>0.358159</td>\n",
       "      <td>0.630244</td>\n",
       "      <td>0.195771</td>\n",
       "      <td>0.291866</td>\n",
       "      <td>0.217294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.786275</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.371253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2017-08-02</td>\n",
       "      <td>0.596744</td>\n",
       "      <td>0.441076</td>\n",
       "      <td>0.395942</td>\n",
       "      <td>0.666906</td>\n",
       "      <td>0.156326</td>\n",
       "      <td>0.126941</td>\n",
       "      <td>0.070381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.796200</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2017-11-03</td>\n",
       "      <td>0.460726</td>\n",
       "      <td>0.312999</td>\n",
       "      <td>0.461417</td>\n",
       "      <td>0.723520</td>\n",
       "      <td>0.152215</td>\n",
       "      <td>0.298045</td>\n",
       "      <td>0.238805</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800215</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.308952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018-02-02</td>\n",
       "      <td>0.414615</td>\n",
       "      <td>0.274157</td>\n",
       "      <td>0.495837</td>\n",
       "      <td>0.750255</td>\n",
       "      <td>0.146371</td>\n",
       "      <td>0.466383</td>\n",
       "      <td>0.383919</td>\n",
       "      <td>0.595233</td>\n",
       "      <td>0.805576</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.414382</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2018-05-02</td>\n",
       "      <td>0.668612</td>\n",
       "      <td>0.518292</td>\n",
       "      <td>0.494127</td>\n",
       "      <td>0.748972</td>\n",
       "      <td>0.137059</td>\n",
       "      <td>0.255188</td>\n",
       "      <td>0.373502</td>\n",
       "      <td>0.450203</td>\n",
       "      <td>0.445931</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.482517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>0.500945</td>\n",
       "      <td>0.348660</td>\n",
       "      <td>0.541991</td>\n",
       "      <td>0.783298</td>\n",
       "      <td>0.139708</td>\n",
       "      <td>0.124917</td>\n",
       "      <td>0.286204</td>\n",
       "      <td>0.663819</td>\n",
       "      <td>0.200562</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.629409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2018-11-05</td>\n",
       "      <td>0.232923</td>\n",
       "      <td>0.139363</td>\n",
       "      <td>0.669134</td>\n",
       "      <td>0.860674</td>\n",
       "      <td>0.140205</td>\n",
       "      <td>0.294316</td>\n",
       "      <td>0.356260</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.195422</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.642154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073851</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2019-01-30</td>\n",
       "      <td>0.492399</td>\n",
       "      <td>0.340938</td>\n",
       "      <td>0.586748</td>\n",
       "      <td>0.812626</td>\n",
       "      <td>0.106711</td>\n",
       "      <td>0.350290</td>\n",
       "      <td>0.468781</td>\n",
       "      <td>0.427688</td>\n",
       "      <td>0.632096</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.278677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>0.511000</td>\n",
       "      <td>0.357851</td>\n",
       "      <td>0.607287</td>\n",
       "      <td>0.825282</td>\n",
       "      <td>0.070602</td>\n",
       "      <td>0.093774</td>\n",
       "      <td>0.135298</td>\n",
       "      <td>0.514792</td>\n",
       "      <td>0.192000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>0.716236</td>\n",
       "      <td>0.573746</td>\n",
       "      <td>0.644579</td>\n",
       "      <td>0.847085</td>\n",
       "      <td>0.068477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023193</td>\n",
       "      <td>0.459057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>0.749092</td>\n",
       "      <td>0.614214</td>\n",
       "      <td>0.780106</td>\n",
       "      <td>0.915515</td>\n",
       "      <td>0.090128</td>\n",
       "      <td>0.175137</td>\n",
       "      <td>0.251750</td>\n",
       "      <td>0.523620</td>\n",
       "      <td>0.071801</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.216096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029682</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>0.799377</td>\n",
       "      <td>0.679983</td>\n",
       "      <td>0.801597</td>\n",
       "      <td>0.925044</td>\n",
       "      <td>0.141261</td>\n",
       "      <td>0.359080</td>\n",
       "      <td>0.516477</td>\n",
       "      <td>0.095642</td>\n",
       "      <td>0.407478</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.543793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>0.707954</td>\n",
       "      <td>0.563837</td>\n",
       "      <td>0.896741</td>\n",
       "      <td>0.963672</td>\n",
       "      <td>0.141940</td>\n",
       "      <td>0.033009</td>\n",
       "      <td>0.078704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.249688</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.563300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2020-07-31</td>\n",
       "      <td>0.682069</td>\n",
       "      <td>0.533595</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.107431</td>\n",
       "      <td>0.026948</td>\n",
       "      <td>0.039895</td>\n",
       "      <td>0.069485</td>\n",
       "      <td>0.227398</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.638195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0  2012-04-25  0.786808  0.663086  0.011931  0.035571  1.000000  1.000000   \n",
       "1  2012-07-25  0.776629  0.649631  0.006912  0.020817  0.565625  0.650950   \n",
       "2  2012-10-31  0.707845  0.563708  0.017641  0.051999  0.666490  0.777428   \n",
       "3  2013-01-24  0.751952  0.617827  0.034704  0.098949  0.167814  0.568224   \n",
       "4  2013-04-24  0.939410  0.892103  0.000000  0.000000  0.059409  0.412637   \n",
       "5  2013-07-24  1.000000  1.000000  0.061922  0.167797  0.000000  0.258043   \n",
       "6  2013-10-30  0.864077  0.772215  0.080637  0.211303  0.071725  0.405263   \n",
       "7  2014-01-28  0.706357  0.561941  0.101279  0.256077  0.100912  0.498011   \n",
       "8  2014-04-24  0.828017  0.719689  0.093698  0.240003  0.232948  0.467587   \n",
       "9  2014-07-23  0.683210  0.534905  0.136333  0.325314  0.237416  0.337811   \n",
       "10 2014-10-27  0.155607  0.089480  0.217090  0.458575  0.163467  0.408232   \n",
       "11 2015-01-28  0.248397  0.149835  0.232382  0.480440  0.285318  0.620497   \n",
       "12 2015-04-28  0.286054  0.176050  0.198894  0.431290  0.372089  0.564704   \n",
       "13 2015-07-22  0.167869  0.097130  0.249273  0.503534  0.267000  0.389583   \n",
       "14 2015-10-28  0.206964  0.122170  0.337421  0.608692  0.303606  0.506796   \n",
       "15 2016-01-27  0.000000  0.000000  0.287564  0.552156  0.307214  0.584318   \n",
       "16 2016-04-27  0.469973  0.321046  0.305697  0.573541  0.241066  0.348894   \n",
       "17 2016-07-27  0.506295  0.353536  0.331090  0.601895  0.109718  0.134933   \n",
       "18 2016-10-26  0.555977  0.400384  0.362667  0.634790  0.209922  0.358419   \n",
       "19 2017-02-01  0.395244  0.258450  0.360283  0.632392  0.156405  0.469503   \n",
       "20 2017-05-03  0.599263  0.443661  0.358159  0.630244  0.195771  0.291866   \n",
       "21 2017-08-02  0.596744  0.441076  0.395942  0.666906  0.156326  0.126941   \n",
       "22 2017-11-03  0.460726  0.312999  0.461417  0.723520  0.152215  0.298045   \n",
       "23 2018-02-02  0.414615  0.274157  0.495837  0.750255  0.146371  0.466383   \n",
       "24 2018-05-02  0.668612  0.518292  0.494127  0.748972  0.137059  0.255188   \n",
       "25 2018-08-01  0.500945  0.348660  0.541991  0.783298  0.139708  0.124917   \n",
       "26 2018-11-05  0.232923  0.139363  0.669134  0.860674  0.140205  0.294316   \n",
       "27 2019-01-30  0.492399  0.340938  0.586748  0.812626  0.106711  0.350290   \n",
       "28 2019-05-01  0.511000  0.357851  0.607287  0.825282  0.070602  0.093774   \n",
       "29 2019-07-31  0.716236  0.573746  0.644579  0.847085  0.068477  0.000000   \n",
       "30 2019-10-31  0.749092  0.614214  0.780106  0.915515  0.090128  0.175137   \n",
       "31 2020-01-29  0.799377  0.679983  0.801597  0.925044  0.141261  0.359080   \n",
       "32 2020-05-01  0.707954  0.563837  0.896741  0.963672  0.141940  0.033009   \n",
       "33 2020-07-31  0.682069  0.533595  1.000000  1.000000  0.107431  0.026948   \n",
       "\n",
       "          7         8         9   ...   37   38        39   40        41   42  \\\n",
       "0   1.000000  1.000000  1.000000  ...  1.0  0.0  0.353778  0.0  0.000000  0.0   \n",
       "1   0.603353  0.000000  0.997016  ...  1.0  0.0  0.353778  0.0  0.000000  0.0   \n",
       "2   0.733998  1.000000  0.968144  ...  1.0  0.0  0.353778  0.0  0.000000  1.0   \n",
       "3   0.496380  0.622115  0.856895  ...  1.0  0.0  0.353778  0.0  0.000000  0.0   \n",
       "4   0.310148  1.000000  0.859870  ...  0.0  0.0  0.538709  0.0  0.000000  0.0   \n",
       "5   0.100323  1.000000  0.849345  ...  0.0  0.0  0.418530  0.0  0.000000  0.0   \n",
       "6   0.290171  1.000000  0.777455  ...  1.0  0.0  0.427019  0.0  0.000000  1.0   \n",
       "7   0.381372  0.000000  0.751768  ...  1.0  0.0  0.311000  0.0  0.000000  0.0   \n",
       "8   0.354666  0.848017  0.446036  ...  1.0  0.0  0.364034  0.0  0.000000  0.0   \n",
       "9   0.203833  0.000000  0.656839  ...  1.0  0.0  0.435719  0.0  0.000000  0.0   \n",
       "10  0.285186  0.000000  0.550421  ...  1.0  0.0  0.503138  0.0  0.000000  1.0   \n",
       "11  0.511498  0.732363  0.847544  ...  1.0  0.0  1.000000  0.0  0.000000  0.0   \n",
       "12  0.443041  1.000000  0.876484  ...  1.0  0.0  0.961304  0.0  0.000000  0.0   \n",
       "13  0.277159  1.000000  0.873418  ...  1.0  0.0  0.962243  0.0  0.000000  0.0   \n",
       "14  0.394610  1.000000  0.838631  ...  1.0  0.0  0.832222  0.0  0.000000  1.0   \n",
       "15  0.514945  0.000000  0.699231  ...  1.0  0.0  0.107750  0.0  0.000000  0.0   \n",
       "16  0.212845  1.000000  0.909675  ...  1.0  0.0  0.008881  0.0  0.000000  0.0   \n",
       "17  0.000000  0.000000  0.793928  ...  1.0  0.0  0.000000  0.0  0.000000  0.0   \n",
       "18  0.247191  0.000000  0.773263  ...  1.0  0.0  0.101902  0.0  0.000000  1.0   \n",
       "19  0.393601  0.000000  0.679198  ...  1.0  0.0  0.334134  0.0  0.000000  0.0   \n",
       "20  0.217294  0.000000  0.786275  ...  1.0  0.0  0.371253  0.0  0.000000  0.0   \n",
       "21  0.070381  0.000000  0.796200  ...  1.0  0.0  0.306942  0.0  1.000000  0.0   \n",
       "22  0.238805  0.000000  0.800215  ...  1.0  0.0  0.308952  0.0  1.000000  1.0   \n",
       "23  0.383919  0.595233  0.805576  ...  1.0  0.0  0.414382  0.0  1.000000  0.0   \n",
       "24  0.373502  0.450203  0.445931  ...  1.0  0.0  0.482517  0.0  1.000000  0.0   \n",
       "25  0.286204  0.663819  0.200562  ...  1.0  0.0  0.629409  0.0  0.071902  0.0   \n",
       "26  0.356260  1.000000  0.195422  ...  1.0  0.0  0.642154  0.0  0.073851  1.0   \n",
       "27  0.468781  0.427688  0.632096  ...  1.0  0.0  0.278677  0.0  0.068583  0.0   \n",
       "28  0.135298  0.514792  0.192000  ...  1.0  0.0  0.183503  0.0  0.073824  0.0   \n",
       "29  0.023193  0.459057  0.000000  ...  1.0  0.0  0.160822  0.0  0.044981  0.0   \n",
       "30  0.251750  0.523620  0.071801  ...  1.0  0.0  0.216096  0.0  0.029682  1.0   \n",
       "31  0.516477  0.095642  0.407478  ...  1.0  0.0  0.543793  0.0  0.000000  0.0   \n",
       "32  0.078704  0.000000  0.249688  ...  1.0  0.0  0.563300  0.0  0.000000  0.0   \n",
       "33  0.039895  0.069485  0.227398  ...  1.0  0.0  0.638195  0.0  0.000000  0.0   \n",
       "\n",
       "     43   44   45   46  \n",
       "0   0.0  1.0  0.0  0.0  \n",
       "1   0.0  0.0  1.0  0.0  \n",
       "2   0.0  0.0  0.0  0.0  \n",
       "3   1.0  0.0  0.0  0.0  \n",
       "4   0.0  1.0  0.0  0.0  \n",
       "5   0.0  0.0  1.0  0.0  \n",
       "6   0.0  0.0  0.0  0.0  \n",
       "7   1.0  0.0  0.0  0.0  \n",
       "8   0.0  1.0  0.0  0.0  \n",
       "9   0.0  0.0  1.0  0.0  \n",
       "10  0.0  0.0  0.0  0.0  \n",
       "11  1.0  0.0  0.0  0.0  \n",
       "12  0.0  1.0  0.0  0.0  \n",
       "13  0.0  0.0  1.0  0.0  \n",
       "14  0.0  0.0  0.0  0.0  \n",
       "15  1.0  0.0  0.0  0.0  \n",
       "16  0.0  1.0  0.0  0.0  \n",
       "17  0.0  0.0  1.0  0.0  \n",
       "18  0.0  0.0  0.0  0.0  \n",
       "19  1.0  0.0  0.0  0.0  \n",
       "20  0.0  1.0  0.0  0.0  \n",
       "21  0.0  0.0  1.0  0.0  \n",
       "22  0.0  0.0  0.0  0.0  \n",
       "23  1.0  0.0  0.0  0.0  \n",
       "24  0.0  1.0  0.0  0.0  \n",
       "25  0.0  0.0  1.0  0.0  \n",
       "26  0.0  0.0  0.0  0.0  \n",
       "27  1.0  0.0  0.0  0.0  \n",
       "28  0.0  1.0  0.0  0.0  \n",
       "29  0.0  0.0  1.0  0.0  \n",
       "30  0.0  0.0  0.0  0.0  \n",
       "31  1.0  0.0  0.0  0.0  \n",
       "32  0.0  1.0  0.0  0.0  \n",
       "33  0.0  0.0  1.0  0.0  \n",
       "\n",
       "[34 rows x 47 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# funktioniert\n",
    "filed_col = reports_df.filed.reset_index().drop(['i_date'], axis = 1).filed\n",
    "print(filed_col.shape)\n",
    "result = pd.concat([filed_col, new_df], axis=1, ignore_index=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(\n",
    "     {\n",
    "         \"A\": [\"A0\", \"A1\", \"A2\", \"A3\"],\n",
    "         \"B\": [\"B0\", \"B1\", \"B2\", \"B3\"],\n",
    "         \"C\": [\"C0\", \"C1\", \"C2\", \"C3\"],\n",
    "         \"D\": [\"D0\", \"D1\", \"D2\", \"D3\"],\n",
    "     },\n",
    "     index=[0, 1, 2, 3],\n",
    " )\n",
    "\n",
    "s1 = pd.Series([\"X0\", \"X1\", \"X2\", \"X3\"], name=\"X\")\n",
    "\n",
    "result = pd.concat([df1, s1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C0</td>\n",
       "      <td>D0</td>\n",
       "      <td>X0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1</td>\n",
       "      <td>B1</td>\n",
       "      <td>C1</td>\n",
       "      <td>D1</td>\n",
       "      <td>X1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2</td>\n",
       "      <td>B2</td>\n",
       "      <td>C2</td>\n",
       "      <td>D2</td>\n",
       "      <td>X2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3</td>\n",
       "      <td>B3</td>\n",
       "      <td>C3</td>\n",
       "      <td>D3</td>\n",
       "      <td>X3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A   B   C   D   X\n",
       "0  A0  B0  C0  D0  X0\n",
       "1  A1  B1  C1  D1  X1\n",
       "2  A2  B2  C2  D2  X2\n",
       "3  A3  B3  C3  D3  X3"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4],\n",
       "       [ 5,  6,  7,  8],\n",
       "       [ 9, 10, 11, 12],\n",
       "       [13, 14, 15, 16],\n",
       "       [17, 18, 19, 20],\n",
       "       [21, 22, 23, 24],\n",
       "       [25, 26, 27, 28],\n",
       "       [29, 30, 31, 32]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_np = np.arange(1, 33).reshape(8,4)\n",
    "data_rows = input_np.shape[0]\n",
    "input_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 3, 4)\n"
     ]
    }
   ],
   "source": [
    "test_lookback = 3\n",
    "nr_of_sequences = data_rows - test_lookback + 1\n",
    "\n",
    "test_inputs = np.zeros((nr_of_sequences, test_lookback, 4))\n",
    "print(test_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(lookback, len(np_df_features)):\n",
    "#    inputs[i-lookback] = np_df_features[i-lookback:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, nr_of_sequences):\n",
    "    test_inputs[i] = input_np[i : i + test_lookback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 3, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 1.,  2.,  3.,  4.],\n",
       "        [ 5.,  6.,  7.,  8.],\n",
       "        [ 9., 10., 11., 12.]],\n",
       "\n",
       "       [[ 5.,  6.,  7.,  8.],\n",
       "        [ 9., 10., 11., 12.],\n",
       "        [13., 14., 15., 16.]],\n",
       "\n",
       "       [[ 9., 10., 11., 12.],\n",
       "        [13., 14., 15., 16.],\n",
       "        [17., 18., 19., 20.]],\n",
       "\n",
       "       [[13., 14., 15., 16.],\n",
       "        [17., 18., 19., 20.],\n",
       "        [21., 22., 23., 24.]],\n",
       "\n",
       "       [[17., 18., 19., 20.],\n",
       "        [21., 22., 23., 24.],\n",
       "        [25., 26., 27., 28.]],\n",
       "\n",
       "       [[21., 22., 23., 24.],\n",
       "        [25., 26., 27., 28.],\n",
       "        [29., 30., 31., 32.]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_inputs.shape)\n",
    "test_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 3, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 1.,  2.,  3.,  4.],\n",
       "        [ 5.,  6.,  7.,  8.],\n",
       "        [ 9., 10., 11., 12.]],\n",
       "\n",
       "       [[ 5.,  6.,  7.,  8.],\n",
       "        [ 9., 10., 11., 12.],\n",
       "        [13., 14., 15., 16.]],\n",
       "\n",
       "       [[ 9., 10., 11., 12.],\n",
       "        [13., 14., 15., 16.],\n",
       "        [17., 18., 19., 20.]],\n",
       "\n",
       "       [[13., 14., 15., 16.],\n",
       "        [17., 18., 19., 20.],\n",
       "        [21., 22., 23., 24.]],\n",
       "\n",
       "       [[17., 18., 19., 20.],\n",
       "        [21., 22., 23., 24.],\n",
       "        [25., 26., 27., 28.]],\n",
       "\n",
       "       [[21., 22., 23., 24.],\n",
       "        [25., 26., 27., 28.],\n",
       "        [29., 30., 31., 32.]]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs = test_inputs.reshape(-1, test_lookback, 4)\n",
    "print (test_inputs.shape)\n",
    "test_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.],\n",
       "       [ 5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15., 16.],\n",
       "       [ 9., 10., 11., 12., 13., 14., 15., 16., 17., 18., 19., 20.],\n",
       "       [13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24.],\n",
       "       [17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27., 28.],\n",
       "       [21., 22., 23., 24., 25., 26., 27., 28., 29., 30., 31., 32.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat = test_inputs.reshape(-1, test_lookback * 4)\n",
    "flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0],\n",
       " [5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0],\n",
       " [9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0],\n",
       " [13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0],\n",
       " [17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0],\n",
       " [21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0]]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...\n",
       "1    [5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13...\n",
       "2    [9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0...\n",
       "3    [13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20....\n",
       "4    [17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24....\n",
       "5    [21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28....\n",
       "dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [[1.0, 2.0, 3.0, 4.0], [5.0, 6.0, 7.0, 8.0], [...\n",
       "1    [[5.0, 6.0, 7.0, 8.0], [9.0, 10.0, 11.0, 12.0]...\n",
       "2    [[9.0, 10.0, 11.0, 12.0], [13.0, 14.0, 15.0, 1...\n",
       "3    [[13.0, 14.0, 15.0, 16.0], [17.0, 18.0, 19.0, ...\n",
       "4    [[17.0, 18.0, 19.0, 20.0], [21.0, 22.0, 23.0, ...\n",
       "5    [[21.0, 22.0, 23.0, 24.0], [25.0, 26.0, 27.0, ...\n",
       "dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(flat.tolist()).apply(lambda field: np.array(field).reshape(test_lookback, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
